{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436d5005-d6a7-4f26-b588-aa34d4d5c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_response(task_query: str, inference_model, sequence_tokenizer) -> str:\n",
    "    processing_device = \"cuda:0\"\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    Here is a task that requires an informative response. Please complete the task based on the provided instruction.\n",
    "\n",
    "    ### Instruction:\n",
    "    {user_task_query}\n",
    "\n",
    "    ### Completion:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the template with the user's query\n",
    "    task_prompt = prompt_template.format(user_task_query=task_query)\n",
    "\n",
    "    # Encoding the prompt for the model\n",
    "    encoded_input = sequence_tokenizer(task_prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "\n",
    "    # Sending the encoded input to the designated processing device\n",
    "    model_input_tensor = encoded_input.to(processing_device)\n",
    "\n",
    "    # Generating tokens from the model based on the input\n",
    "    generated_token_ids = inference_model.generate(\n",
    "        **model_input_tensor, \n",
    "        max_new_tokens=1000, \n",
    "        do_sample=True, \n",
    "        pad_token_id=sequence_tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    # Decoding the generated tokens to form the response\n",
    "    generated_response = sequence_tokenizer.batch_decode(generated_token_ids, skip_special_tokens=True)\n",
    "    \n",
    "    return generated_response[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed9c02a5-245f-412b-92ff-755c6f2e2522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib/python3.9/site-packages (23.3.1)\n",
      "Requirement already satisfied: bitsandbytes in /opt/app-root/lib/python3.9/site-packages (0.41.2.post2)\n",
      "Collecting git+https://github.com/huggingface/transformers.git\n",
      "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-6_ruube8\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-6_ruube8\n",
      "  Resolved https://github.com/huggingface/transformers.git to commit 083e36923a19650fa264c4173db2f63ab124bb27\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers==4.36.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.36.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers==4.36.0.dev0) (2023.7.22)\n",
      "Collecting git+https://github.com/huggingface/peft.git\n",
      "  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-4zhz2aor\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-4zhz2aor\n",
      "  Resolved https://github.com/huggingface/peft.git to commit 2b901ee57230559aaf39867c7698f6aca3617162\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (2.1.1)\n",
      "Requirement already satisfied: transformers in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (4.36.0.dev0)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (4.66.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (0.25.0.dev0)\n",
      "Requirement already satisfied: safetensors in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (0.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/app-root/lib/python3.9/site-packages (from peft==0.6.3.dev0) (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.17.0->peft==0.6.3.dev0) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.13.0->peft==0.6.3.dev0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.6.3.dev0) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers->peft==0.6.3.dev0) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/app-root/lib/python3.9/site-packages (from transformers->peft==0.6.3.dev0) (0.15.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.13.0->peft==0.6.3.dev0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.6.3.dev0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch>=1.13.0->peft==0.6.3.dev0) (1.3.0)\n",
      "Collecting git+https://github.com/huggingface/accelerate.git\n",
      "  Cloning https://github.com/huggingface/accelerate.git to /tmp/pip-req-build-kq7q1b0i\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/accelerate.git /tmp/pip-req-build-kq7q1b0i\n",
      "  Resolved https://github.com/huggingface/accelerate.git to commit 68d63ee15f0faf12429d686b7eca3ee0afb1760d\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from accelerate==0.25.0.dev0) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from accelerate==0.25.0.dev0) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from accelerate==0.25.0.dev0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/app-root/lib/python3.9/site-packages (from accelerate==0.25.0.dev0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/app-root/lib/python3.9/site-packages (from accelerate==0.25.0.dev0) (2.1.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/app-root/lib/python3.9/site-packages (from accelerate==0.25.0.dev0) (0.19.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/app-root/lib/python3.9/site-packages (from accelerate==0.25.0.dev0) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.25.0.dev0) (12.3.101)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate==0.25.0.dev0) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub->accelerate==0.25.0.dev0) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate==0.25.0.dev0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->huggingface-hub->accelerate==0.25.0.dev0) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch>=1.10.0->accelerate==0.25.0.dev0) (1.3.0)\n",
      "Requirement already satisfied: datasets in /opt/app-root/lib/python3.9/site-packages (2.15.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib/python3.9/site-packages (from datasets) (1.26.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/app-root/lib/python3.9/site-packages (from datasets) (0.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/app-root/lib/python3.9/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/app-root/lib/python3.9/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/app-root/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib/python3.9/site-packages (from datasets) (3.8.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.18.0 in /opt/app-root/lib/python3.9/site-packages (from datasets) (0.19.4)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib/python3.9/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/app-root/lib/python3.9/site-packages (from huggingface-hub>=0.18.0->datasets) (4.7.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/app-root/lib/python3.9/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/app-root/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/app-root/lib/python3.9/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (4.45.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/app-root/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.16.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: scipy in /opt/app-root/lib/python3.9/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/app-root/lib/python3.9/site-packages (from scipy) (1.26.2)\n",
      "Requirement already satisfied: ipywidgets in /opt/app-root/lib/python3.9/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /opt/app-root/lib/python3.9/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: backcall in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.7.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/app-root/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/app-root/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/app-root/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /opt/app-root/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in /opt/app-root/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: trl in /opt/app-root/lib/python3.9/site-packages (0.7.4)\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/app-root/lib/python3.9/site-packages (from trl) (2.1.1)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /opt/app-root/lib/python3.9/site-packages (from trl) (4.36.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/app-root/lib/python3.9/site-packages (from trl) (1.26.2)\n",
      "Requirement already satisfied: accelerate in /opt/app-root/lib/python3.9/site-packages (from trl) (0.25.0.dev0)\n",
      "Requirement already satisfied: datasets in /opt/app-root/lib/python3.9/site-packages (from trl) (2.15.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/app-root/lib/python3.9/site-packages (from trl) (0.5.17)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.4.0->trl) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (0.19.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (2023.10.3)\n",
      "Requirement already satisfied: requests in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib/python3.9/site-packages (from transformers>=4.18.0->trl) (4.66.1)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/app-root/lib/python3.9/site-packages (from tyro>=0.5.11->trl) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/app-root/lib/python3.9/site-packages (from tyro>=0.5.11->trl) (13.7.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/app-root/lib/python3.9/site-packages (from tyro>=0.5.11->trl) (1.6.4)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from accelerate->trl) (5.9.5)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/app-root/lib/python3.9/site-packages (from datasets->trl) (14.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/app-root/lib/python3.9/site-packages (from datasets->trl) (0.5)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/app-root/lib/python3.9/site-packages (from datasets->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.9/site-packages (from datasets->trl) (2.1.3)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib/python3.9/site-packages (from datasets->trl) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/app-root/lib/python3.9/site-packages (from datasets->trl) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in /opt/app-root/lib/python3.9/site-packages (from datasets->trl) (3.8.5)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets->trl) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets->trl) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets->trl) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets->trl) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets->trl) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets->trl) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/app-root/lib/python3.9/site-packages (from aiohttp->datasets->trl) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers>=4.18.0->trl) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers>=4.18.0->trl) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests->transformers>=4.18.0->trl) (2023.7.22)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/app-root/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/app-root/lib/python3.9/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets->trl) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets->trl) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/app-root/lib/python3.9/site-packages (from pandas->datasets->trl) (2023.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/app-root/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -U bitsandbytes\n",
    "!pip install  -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install  -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -U git+https://github.com/huggingface/accelerate.git\n",
    "!pip install datasets\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scipy\n",
    "!pip install ipywidgets\n",
    "!pip install  trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75bb7ca9-729e-43cb-8308-b02bbdcf8397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.1.1+cu121\n",
      "CUDA is available.\n",
      "Number of GPU: 1\n",
      "Device 0: Tesla V100-PCIE-16GB\n",
      "_CudaDeviceProperties(name='Tesla V100-PCIE-16GB', major=7, minor=0, total_memory=16151MB, multi_processor_count=80)\n",
      "Memory GB: 15.77 GB\n",
      "GPU Allocated: 0.00 GB\n",
      "GPU Cached:    0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available.\")\n",
    "    print(\"Number of GPU:\", torch.cuda.device_count())\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(torch.cuda.get_device_properties(i))\n",
    "        print(f\"Memory GB: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.2f} GB\")\n",
    "        print(f\"GPU Allocated: {torch.cuda.memory_allocated(i) / 1024 ** 3:.2f} GB\")\n",
    "        print(f\"GPU Cached:    {torch.cuda.memory_reserved(i) / 1024 ** 3:.2f} GB\")\n",
    "        \n",
    "        \n",
    "else:\n",
    "    print(\"CUDA is not available. No GPU detected.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76acbdc-a175-4d6d-bcbd-d6a6915155f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov 29 18:55:48 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-16GB           On  | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              26W / 250W |      4MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a308d105-58ae-43ac-9ee4-6439ccaebc8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "      <th>instruction</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.</td>\n",
       "      <td></td>\n",
       "      <td>For a car, what scams can be plotted with 0% financing vs rebate?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That is kind of the point, one of the hopes is that it incentivizes banks to stop storing money and start injecting it into the economy themselves. Compared to the European Central Bank investing directly into the economy the way the US central bank has been doing. (The Federal Reserve buying mortgage backed securities) On a country level, individual European countries have tried this before in recent times with no noticeable effect.</td>\n",
       "      <td></td>\n",
       "      <td>Why does it matter if a Central Bank has a negative rather than 0% interest rate?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pay off your debt.  As you witnessed, no \"investment\" % is guaranteed.  But your debt payments are... so if you have cash, the best way to \"invest\" it is to pay off your debt.  Since your car is depreciating while your house may be appreciating (don't know but it's possible) you should pay off your car loan first.  You're losing money in more than one way on that investment.</td>\n",
       "      <td></td>\n",
       "      <td>Where should I be investing my money?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Equity options, at least those traded in the American exchanges, actually expire the Saturday after the 3rd Friday of the month.  However, the choice to trade or exercise the options must be specified by the 3rd Friday. This is outlined by the CBOE, who oversees the exchange of equity options.  Their FAQ regarding option expiration can be found at http://www.cboe.com/LearnCenter/Concepts/Beyond/expiration.aspx.</td>\n",
       "      <td></td>\n",
       "      <td>Specifically when do options expire?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Automatic exercisions can be extremely risky, and the closer to the money the options are, the riskier their exercisions are. It is unlikely that the entire account has negative equity since a responsible broker would forcibly close all positions and pursue the holder for the balance of the debt to reduce solvency risk.  Since the broker has automatically exercised a near the money option, it's solvency policy is already risky. Regardless of whether there is negative equity or simply a liability, the least risky course of action is to sell enough of the underlying to satisfy the loan by closing all other positions if necessary as soon as possible. If there is a negative equity after trying to satisfy the loan, the account will need to be funded for the balance of the loan to pay for purchases of the underlying to fully satisfy the loan. Since the underlying can move in such a way to cause this loan to increase, the account should also be funded as soon as possible if necessary. Accounts after exercise For deep in the money exercised options, a call turns into a long underlying on margin while a put turns into a short underlying. The next decision should be based upon risk and position selection.  First, if the position is no longer attractive, it should be closed.  Since it's deep in the money, simply closing out the exposure to the underlying should extinguish the liability as cash is not marginable, so the cash received from the closing out of the position will repay any margin debt. If the position in the underlying is still attractive then the liability should be managed according to one's liability policy and of course to margin limits. In a margin account, closing the underlying positions on the same day as the exercise will only be considered a day trade.  If the positions are closed on any business day after the exercision, there will be no penalty or restriction. Cash option accounts While this is possible, many brokers force an upgrade to a margin account, and the ShareBuilder Options Account Agreement seems ambiguous, but their options trading page implies the upgrade. In a cash account, equities are not marginable, so any margin will trigger a margin call.  If the margin debt did not trigger a margin call then it is unlikely that it is a cash account as margin for any security in a cash account except for certain options trades is 100%. Equities are convertible to cash presumably at the bid, so during a call exercise, the exercisor or exercisor's broker pays cash for the underlying at the exercise price, and any deficit is financed with debt, thus underlying can be sold to satisfy that debt or be sold for cash as one normally would. To preempt a forced exercise as a call holder, one could short the underlying, but this will be more expensive, and since probably no broker allows shorting against the box because of its intended use to circumvent capital gains taxes by fraud.  The least expensive way to trade out of options positions is to close them themselves rather than take delivery.</td>\n",
       "      <td></td>\n",
       "      <td>Negative Balance from Automatic Options Exercise. What to do?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Generally \"default\" means that the company cannot pay off their debts, and since debt holders get paid before equity holders, their equity would be effectively worthless. That said, companies can emerge from Chapter 11 bankruptcy (reorganization) and retain equity value, but it is rare. Most times, stocks are de-listed or frozen on stock exchanges, and company's reorganization plan will cancel all existing equity shares, instead focusing all of their attention on paying back as much debt as possible. If the company issues new equity after reorganizing, it might provide a way for holders of the original equity to exchange their shares for the new equity, but it is rare, and the value is usually significantly less that the value of the original equity.</td>\n",
       "      <td></td>\n",
       "      <td>Approximation of equity value for company in default</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The game is not zero sum. When a friend and I chop down a tree, and build a house from it, the house has value, far greater than the value of a standing tree. Our labor has turned into something of value.  In theory, a company starts from an idea, and offers either a good or service to create value. There are scams that make it seem like a Vegas casino. There are times a stock will trade for well above what it should. When I buy the S&amp;P index at a fair price for 1000 (through an etf or fund) and years later it's 1400, the gain isn't out of someone else's pocket, else the amount of wealth in the world would be fixed and that's not the case. Over time, investors lag the market return for multiple reasons, trading costs, bad timing, etc. Statements such as \"90% lose money\" are hyperbole meant to separate you from your money. A self fulfilling prophesy.   The question of lagging the market is another story - I have no data to support my observation, but I'd imagine that well over 90% lag the broad market. A detailed explanation is too long for this forum, but simply put, there are trading costs. If I invest in an S&amp;P ETF that costs .1% per year, I'll see a return of say 9.9% over decades if the market return is 10%. Over 40 years, this is 4364% compounded, vs the index 4526% compounded, a difference of less than 4% in final wealth. There are load funds that charge more than this just to buy in (5% anyone?).  Lagging by a small fraction is a far cry from 'losing money.'  There is an annual report by a company named Dalbar that tracks investor performance. For the 20 year period ending 12/31/10 the S&amp;P returned 9.14% and Dalbar calculates the average investor had an average return of 3.83%. Pretty bad, but not zero. Since you don't cite a particular article or source, there may be more to the story. Day traders are likely to lose. As are a series of other types of traders in other markets, Forex for one.  While your question may be interesting, its premise of \"many experts say....\" without naming even one leaves room for doubt.  Note - I've updated the link for the 2015 report. And 4 years later, I see that when searching on that 90% statistic, the articles are about day traders. That actually makes sense to me.</td>\n",
       "      <td></td>\n",
       "      <td>Is it true that 90% of investors lose their money?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>In general, you can only be charged for services if there is some kind of contract. The contract doesn't have to be written, but you have to have agreed to it somehow. However, it is possible that you entered into a contract due to some clause in the home purchase contract or the contract with the home owners' association. There are also sometimes services you are legally required to get, such as regular inspection of heating furnaces (though I don't think this translates to automatic contracts). But in any case you would not be liable for services rendered before you entered into the contract, which sounds like it's the case here.</td>\n",
       "      <td></td>\n",
       "      <td>Can a company charge you for services never requested or received?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Being self employed just means you fill out some more forms in your annual self assessment for your \"profit\" from being self employed.  Profit = all the money you receive, minus any tax deductible cost that you spent for making that money (and all the cost must be documented, which means you have a folder with all the receipts and keep it safe). You pay normal income tax on all the profit, which means it is just added to your taxable income. What you do with the profit is up to you; you don't pay yourself a salary, just take the money (make sure you leave enough to pay your taxes).</td>\n",
       "      <td></td>\n",
       "      <td>Working out if I should be registered as self-employed in the UK</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For eToro, just like any other brokerage firm, you can lose your entire capital. I suggest that you invest in one or more exchange-traded funds that track major indexes.  If not, just put your money in fixed deposit accounts; gain a bit of interest and establish an emergency fund first before investing money that you feel you are able to lose.</td>\n",
       "      <td></td>\n",
       "      <td>About eToro investments</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        output  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        That is kind of the point, one of the hopes is that it incentivizes banks to stop storing money and start injecting it into the economy themselves. Compared to the European Central Bank investing directly into the economy the way the US central bank has been doing. (The Federal Reserve buying mortgage backed securities) On a country level, individual European countries have tried this before in recent times with no noticeable effect.   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Pay off your debt.  As you witnessed, no \"investment\" % is guaranteed.  But your debt payments are... so if you have cash, the best way to \"invest\" it is to pay off your debt.  Since your car is depreciating while your house may be appreciating (don't know but it's possible) you should pay off your car loan first.  You're losing money in more than one way on that investment.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Equity options, at least those traded in the American exchanges, actually expire the Saturday after the 3rd Friday of the month.  However, the choice to trade or exercise the options must be specified by the 3rd Friday. This is outlined by the CBOE, who oversees the exchange of equity options.  Their FAQ regarding option expiration can be found at http://www.cboe.com/LearnCenter/Concepts/Beyond/expiration.aspx.   \n",
       "4  Automatic exercisions can be extremely risky, and the closer to the money the options are, the riskier their exercisions are. It is unlikely that the entire account has negative equity since a responsible broker would forcibly close all positions and pursue the holder for the balance of the debt to reduce solvency risk.  Since the broker has automatically exercised a near the money option, it's solvency policy is already risky. Regardless of whether there is negative equity or simply a liability, the least risky course of action is to sell enough of the underlying to satisfy the loan by closing all other positions if necessary as soon as possible. If there is a negative equity after trying to satisfy the loan, the account will need to be funded for the balance of the loan to pay for purchases of the underlying to fully satisfy the loan. Since the underlying can move in such a way to cause this loan to increase, the account should also be funded as soon as possible if necessary. Accounts after exercise For deep in the money exercised options, a call turns into a long underlying on margin while a put turns into a short underlying. The next decision should be based upon risk and position selection.  First, if the position is no longer attractive, it should be closed.  Since it's deep in the money, simply closing out the exposure to the underlying should extinguish the liability as cash is not marginable, so the cash received from the closing out of the position will repay any margin debt. If the position in the underlying is still attractive then the liability should be managed according to one's liability policy and of course to margin limits. In a margin account, closing the underlying positions on the same day as the exercise will only be considered a day trade.  If the positions are closed on any business day after the exercision, there will be no penalty or restriction. Cash option accounts While this is possible, many brokers force an upgrade to a margin account, and the ShareBuilder Options Account Agreement seems ambiguous, but their options trading page implies the upgrade. In a cash account, equities are not marginable, so any margin will trigger a margin call.  If the margin debt did not trigger a margin call then it is unlikely that it is a cash account as margin for any security in a cash account except for certain options trades is 100%. Equities are convertible to cash presumably at the bid, so during a call exercise, the exercisor or exercisor's broker pays cash for the underlying at the exercise price, and any deficit is financed with debt, thus underlying can be sold to satisfy that debt or be sold for cash as one normally would. To preempt a forced exercise as a call holder, one could short the underlying, but this will be more expensive, and since probably no broker allows shorting against the box because of its intended use to circumvent capital gains taxes by fraud.  The least expensive way to trade out of options positions is to close them themselves rather than take delivery.   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Generally \"default\" means that the company cannot pay off their debts, and since debt holders get paid before equity holders, their equity would be effectively worthless. That said, companies can emerge from Chapter 11 bankruptcy (reorganization) and retain equity value, but it is rare. Most times, stocks are de-listed or frozen on stock exchanges, and company's reorganization plan will cancel all existing equity shares, instead focusing all of their attention on paying back as much debt as possible. If the company issues new equity after reorganizing, it might provide a way for holders of the original equity to exchange their shares for the new equity, but it is rare, and the value is usually significantly less that the value of the original equity.   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        The game is not zero sum. When a friend and I chop down a tree, and build a house from it, the house has value, far greater than the value of a standing tree. Our labor has turned into something of value.  In theory, a company starts from an idea, and offers either a good or service to create value. There are scams that make it seem like a Vegas casino. There are times a stock will trade for well above what it should. When I buy the S&P index at a fair price for 1000 (through an etf or fund) and years later it's 1400, the gain isn't out of someone else's pocket, else the amount of wealth in the world would be fixed and that's not the case. Over time, investors lag the market return for multiple reasons, trading costs, bad timing, etc. Statements such as \"90% lose money\" are hyperbole meant to separate you from your money. A self fulfilling prophesy.   The question of lagging the market is another story - I have no data to support my observation, but I'd imagine that well over 90% lag the broad market. A detailed explanation is too long for this forum, but simply put, there are trading costs. If I invest in an S&P ETF that costs .1% per year, I'll see a return of say 9.9% over decades if the market return is 10%. Over 40 years, this is 4364% compounded, vs the index 4526% compounded, a difference of less than 4% in final wealth. There are load funds that charge more than this just to buy in (5% anyone?).  Lagging by a small fraction is a far cry from 'losing money.'  There is an annual report by a company named Dalbar that tracks investor performance. For the 20 year period ending 12/31/10 the S&P returned 9.14% and Dalbar calculates the average investor had an average return of 3.83%. Pretty bad, but not zero. Since you don't cite a particular article or source, there may be more to the story. Day traders are likely to lose. As are a series of other types of traders in other markets, Forex for one.  While your question may be interesting, its premise of \"many experts say....\" without naming even one leaves room for doubt.  Note - I've updated the link for the 2015 report. And 4 years later, I see that when searching on that 90% statistic, the articles are about day traders. That actually makes sense to me.   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              In general, you can only be charged for services if there is some kind of contract. The contract doesn't have to be written, but you have to have agreed to it somehow. However, it is possible that you entered into a contract due to some clause in the home purchase contract or the contract with the home owners' association. There are also sometimes services you are legally required to get, such as regular inspection of heating furnaces (though I don't think this translates to automatic contracts). But in any case you would not be liable for services rendered before you entered into the contract, which sounds like it's the case here.   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Being self employed just means you fill out some more forms in your annual self assessment for your \"profit\" from being self employed.  Profit = all the money you receive, minus any tax deductible cost that you spent for making that money (and all the cost must be documented, which means you have a folder with all the receipts and keep it safe). You pay normal income tax on all the profit, which means it is just added to your taxable income. What you do with the profit is up to you; you don't pay yourself a salary, just take the money (make sure you leave enough to pay your taxes).   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    For eToro, just like any other brokerage firm, you can lose your entire capital. I suggest that you invest in one or more exchange-traded funds that track major indexes.  If not, just put your money in fixed deposit accounts; gain a bit of interest and establish an emergency fund first before investing money that you feel you are able to lose.   \n",
       "\n",
       "  input  \\\n",
       "0         \n",
       "1         \n",
       "2         \n",
       "3         \n",
       "4         \n",
       "5         \n",
       "6         \n",
       "7         \n",
       "8         \n",
       "9         \n",
       "\n",
       "                                                                         instruction  \\\n",
       "0                  For a car, what scams can be plotted with 0% financing vs rebate?   \n",
       "1  Why does it matter if a Central Bank has a negative rather than 0% interest rate?   \n",
       "2                                              Where should I be investing my money?   \n",
       "3                                               Specifically when do options expire?   \n",
       "4                      Negative Balance from Automatic Options Exercise. What to do?   \n",
       "5                               Approximation of equity value for company in default   \n",
       "6                                 Is it true that 90% of investors lose their money?   \n",
       "7                 Can a company charge you for services never requested or received?   \n",
       "8                   Working out if I should be registered as self-employed in the UK   \n",
       "9                                                            About eToro investments   \n",
       "\n",
       "  text  \n",
       "0       \n",
       "1       \n",
       "2       \n",
       "3       \n",
       "4       \n",
       "5       \n",
       "6       \n",
       "7       \n",
       "8       \n",
       "9       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for pandas\n",
    "pd.set_option('display.max_columns', None)  # Show all columns in the DataFrame\n",
    "pd.set_option('display.max_colwidth', None)  # Ensure the full content of each cell is displayed\n",
    "\n",
    "# Load the dataset\n",
    "data = load_dataset(\"gbharti/finance-alpaca\", split='train')\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "df = data.to_pandas()\n",
    "\n",
    "# Display the first 10 rows of the DataFrame\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc1dae57-6c9c-45de-8c99-a07e285283f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Dataset Information:\n",
      "Number of Rows: 68912\n",
      "Number of Columns: 4\n",
      "Column Names: ['output', 'input', 'instruction', 'text']\n",
      "\n",
      "Memory Usage by Column:\n",
      "Index               128\n",
      "output         38370019\n",
      "input           5204184\n",
      "instruction     8246541\n",
      "text            3927984\n",
      "dtype: int64\n",
      "\n",
      "Data Types of Each Column:\n",
      "output         object\n",
      "input          object\n",
      "instruction    object\n",
      "text           object\n",
      "dtype: object\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+sAAALjCAYAAABqJJSQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAACv+ElEQVR4nOzdeVhV5fr/8Q8gm0FkUgRJRVJznkJFylkSjTqZVmqTA+rJA5VysrJTjp0sy6myrFOJDZbpOVmpqeRYipqo5ZCWptkgaDngCAjP749+rK9btsJWhq2+X9e1L91r3etZz7r32rBu1vC4GWOMAAAAAACAy3Av7w4AAAAAAAB7FOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wBwnjFjxsjNza1M1tWxY0d17NjRer9y5Uq5ublp3rx5ZbL+/v37q1atWmWyrkt14sQJDRo0SGFhYXJzc9OwYcNKpN2Cz/mPP/4okfZw9boSvifF0bFjRzVu3Li8u2Gn4GfeypUry7srAOByKNYBXNVSUlLk5uZmvby9vRUeHq64uDi9/PLLOn78eIms5/fff9eYMWO0ZcuWEmmvJLly34rjueeeU0pKioYOHar33ntPDzzwwEXj8/LyNHPmTHXs2FHBwcHy8vJSrVq1NGDAAG3cuLGMel26Zs+eralTp5bLuj/55BN1795dVapUkc1mU3h4uO655x4tX768XPpzvithfy8oUC/0+uijj8q7ixd0LXy/AMBVVCjvDgBAWRg3bpwiIyOVm5urjIwMrVy5UsOGDdPkyZP12WefqWnTplbs008/rSeffNKp9n///XeNHTtWtWrVUvPmzYu93NKlS51az6W4WN/+85//KD8/v9T7cDmWL1+uNm3aaPTo0UXGnj59Wj179tTixYvVvn17PfXUUwoODta+ffv08ccfa9asWdq/f7+qV69eBj0vPbNnz9a2bdtK7CqD4jDGaODAgUpJSVGLFi2UnJyssLAwHThwQJ988om6dOmiNWvW6KabbiqzPjlyqd/Fiymt78kjjzyiVq1aFZoeExNT4usqCdfK9wsAXAXFOoBrQvfu3dWyZUvr/ciRI7V8+XLddttt+tvf/qbvv/9ePj4+kqQKFSqoQoXS/fF46tQp+fr6ymazlep6iuLp6Vmu6y+OgwcPqmHDhsWKHTFihBYvXqwpU6YUKmRHjx6tKVOmlEIPL8wYozNnzlj7livLz89XTk6OvL29Hc6fNGmSUlJSrD9ynXuryL/+9S+99957pf69KS+l9T1p166d7rrrrlJpuzS42vcLAK52XAYP4JrVuXNnPfPMM/r555/1/vvvW9Md3bOempqqtm3bKjAwUH5+fqpXr56eeuopSX9d0lpwdmzAgAHWpawpKSmS/u8+0fT0dLVv316+vr7Wsuffs14gLy9PTz31lMLCwlSxYkX97W9/0y+//GIXU6tWLfXv37/Qsue2WVTfHN2Le/LkSf3zn/9UjRo15OXlpXr16umll16SMcYuzs3NTUlJSZo/f74aN24sLy8vNWrUSIsXL3ac8PMcPHhQCQkJCg0Nlbe3t5o1a6ZZs2ZZ8wsuFd67d68WLlxo9X3fvn0O2/v111/1xhtv6JZbbnF4xtnDw0OPPfZYobN+R48eVf/+/RUYGKiAgAANGDBAp06dsouZOXOmOnfurKpVq8rLy0sNGzbU66+/XmgdtWrV0m233aYlS5aoZcuW8vHx0RtvvOFUG5L0xRdfqEOHDqpUqZL8/f3VqlUrzZ49W9Jfn+/ChQv1888/Wzk59zPMzs7W6NGjVadOHXl5ealGjRp6/PHHlZ2dbbeOgs/vgw8+UKNGjeTl5XXBz+706dOaMGGC6tevr5deesnhMx0eeOABtW7d2nr/008/6e6771ZwcLB8fX3Vpk0bLVy40G6ZgttUzv9MHd3HXPA92rFjhzp16iRfX19dd911mjhxot1yF9vff/zxR/Xq1UthYWHy9vZW9erV1adPHx07dszhdhc4/3uyb98+ubm56aWXXtKbb76p2rVry8vLS61atdI333xz0bacVVL7zbkulsMLuZTv1+bNm9W9e3f5+/vLz89PXbp00bp164pcV3F+tkn/t598/PHHGjt2rK677jpVqlRJd911l44dO6bs7GwNGzZMVatWlZ+fnwYMGHDB78Gl/hwDgNJ0df4JHACK6YEHHtBTTz2lpUuXavDgwQ5jtm/frttuu01NmzbVuHHj5OXlpd27d2vNmjWSpAYNGmjcuHEaNWqUhgwZonbt2kmS3eXAf/75p7p3764+ffro/vvvV2ho6EX79e9//1tubm564okndPDgQU2dOlWxsbHasmWLU2dpi9O3cxlj9Le//U0rVqxQQkKCmjdvriVLlmjEiBH67bffCp05+/rrr/W///1P//jHP1SpUiW9/PLL6tWrl/bv36/KlStfsF+nT59Wx44dtXv3biUlJSkyMlJz585V//79dfToUT366KNq0KCB3nvvPQ0fPlzVq1fXP//5T0lSSEiIwza/+OILnT17tsh72s93zz33KDIyUhMmTNCmTZv01ltvqWrVqnrhhResmNdff12NGjXS3/72N1WoUEGff/65/vGPfyg/P1+JiYl27e3atUt9+/bV3//+dw0ePFj16tVzqo2UlBQNHDhQjRo10siRIxUYGKjNmzdr8eLFuvfee/Wvf/1Lx44d06+//mp9Hn5+fpL+Ojv+t7/9TV9//bWGDBmiBg0aaOvWrZoyZYp++OEHzZ8/366vy5cv18cff6ykpCRVqVLlgg9R+/rrr3X48GENGzZMHh4eReY0MzNTN910k06dOqVHHnlElStX1qxZs/S3v/1N8+bN05133llkG44cOXJE3bp1U8+ePXXPPfdo3rx5euKJJ9SkSRN17979ovt7Tk6O4uLilJ2drYcfflhhYWH67bfftGDBAh09elQBAQFO92f27Nk6fvy4/v73v8vNzU0TJ05Uz5499dNPPxXrbPzx48cdPuCwcuXK1h9ESmq/KW4OL8TZ79f27dvVrl07+fv76/HHH5enp6feeOMNdezYUatWrVJ0dHSx2imOCRMmyMfHR08++aR2796tV155RZ6ennJ3d9eRI0c0ZswYrVu3TikpKYqMjNSoUaPslr/Un2MAUOoMAFzFZs6caSSZb7755oIxAQEBpkWLFtb70aNHm3N/PE6ZMsVIMocOHbpgG998842RZGbOnFloXocOHYwkM2PGDIfzOnToYL1fsWKFkWSuu+46k5WVZU3/+OOPjSQzbdo0a1pERITp169fkW1erG/9+vUzERER1vv58+cbSebZZ5+1i7vrrruMm5ub2b17tzVNkrHZbHbTvv32WyPJvPLKK4XWda6pU6caSeb999+3puXk5JiYmBjj5+dnt+0REREmPj7+ou0ZY8zw4cONJLN58+YiY435v8954MCBdtPvvPNOU7lyZbtpp06dKrR8XFycuf766+2mRUREGElm8eLFheKL08bRo0dNpUqVTHR0tDl9+rRdbH5+vvX/+Ph4u8+twHvvvWfc3d3NV199ZTd9xowZRpJZs2aNNU2ScXd3N9u3by/UzvmmTZtmJJlPPvmkyFhjjBk2bJiRZNeP48ePm8jISFOrVi2Tl5dnjPm/7+fevXvtli/4HqxYscKaVvA9evfdd61p2dnZJiwszPTq1cuadqH9ffPmzUaSmTt3brG24Vznf0/27t1rJJnKlSubw4cPW9M//fRTI8l8/vnnF22vYPsu9Dpw4IAVW5L7TXFz6Iiz368ePXoYm81m9uzZY037/fffTaVKlUz79u2taY4+6+L+bCtYtnHjxiYnJ8ea3rdvX+Pm5ma6d+9ut3xMTEyh783l/BwDgNLGZfAArnl+fn4XfSp8YGCgJOnTTz+95IdMeXl5acCAAcWOf/DBB1WpUiXr/V133aVq1app0aJFl7T+4lq0aJE8PDz0yCOP2E3/5z//KWOMvvjiC7vpsbGxql27tvW+adOm8vf3108//VTkesLCwtS3b19rmqenpx555BGdOHFCq1atcrrvWVlZkmSXt+J46KGH7N63a9dOf/75p9WeJLurGY4dO6Y//vhDHTp00E8//VToEurIyEjFxcUVWk9x2khNTdXx48f15JNPFrp3vDjDCc6dO1cNGjRQ/fr19ccff1ivzp07S5JWrFhhF9+hQ4diPQ/A2dwuWrRIrVu3Vtu2ba1pfn5+GjJkiPbt26cdO3YUq53z+fn56f7777fe22w2tW7dusj9TZJ15nzJkiWFbnO4VL1791ZQUJD1vuBMfnH6I0mjRo1SampqoVdwcLAVU9L7zaXm0Jl9IC8vT0uXLlWPHj10/fXXW9OrVaume++9V19//bXd9+tyPfjgg3ZXMkRHR1sPRDxXdHS0fvnlF509e9Zu+qX+HAOA0kaxDuCad+LEiYsegPbu3Vs333yzBg0apNDQUPXp00cff/yxU4X7dddd59TD5OrWrWv33s3NTXXq1Lng/dol5eeff1Z4eHihfDRo0MCaf66aNWsWaiMoKEhHjhwpcj1169aVu7v9r6ELrac4/P39Jcnp4fjO34aC4uvcbVizZo1iY2NVsWJFBQYGKiQkxHrugKNi3ZHitLFnzx5JuuSxsH/88Udt375dISEhdq8bbrhB0l/PCShOX8/nbG5//vln6/L/c13O5ytJ1atXL1R8Fmd/k/7a1uTkZL311luqUqWK4uLiNH369CLvV7+Y4uw7F9OkSRPFxsYWep37s6Kk95tLzaEz+8ChQ4d06tSpC+4D+fn5hZ7BcTnO/xwK/jBTo0aNQtPz8/MLfeaX+nMMAEobxTqAa9qvv/6qY8eOqU6dOheM8fHx0erVq/Xll1/qgQce0HfffafevXvrlltuUV5eXrHWUxpPA7/Qmdbi9qkkXOj+ZXPew+jKQv369SVJW7dudWq5orZhz5496tKli/744w9NnjxZCxcuVGpqqoYPHy5Jhf5o4+izdraNS5Wfn68mTZo4PFubmpqqf/zjH0X21ZFLzW1RnN2HL3d/mzRpkr777js99dRTOn36tB555BE1atRIv/76a/E6XML9KUpp7DeX2ufS2gccKan9orjb6ko/xwDgXDxgDsA17b333pMkh5ctn8vd3V1dunRRly5dNHnyZD333HP617/+pRUrVig2NrZYlyg748cff7R7b4zR7t277caDDwoK0tGjRwst+/PPP9tdeupM3yIiIvTll1/q+PHjdmfXd+7cac0vCREREfruu++Un59vd3b9ctbTvXt3eXh46P3333f6IXMX8/nnnys7O1ufffaZ3Rm48y8pL4k2Ci7F3bZt20X/gHShz7R27dr69ttv1aVLlxLdJ9u2baugoCB9+OGHeuqpp4p8yFxERIR27dpVaPr5n2/Bmejz9+NLPfMuFb2/N2nSRE2aNNHTTz+ttWvX6uabb9aMGTP07LPPXvI6S0tJ7zeXw5nvV0hIiHx9fS+4D7i7uxc6632u4v5sA4CrHWfWAVyzli9frvHjxysyMlL33XffBeMOHz5caFrz5s0lyRoGqGLFipIKFx2X6t1337W73HTevHk6cOCA3dOaa9eurXXr1iknJ8eatmDBgkKXlzrTt1tvvVV5eXl69dVX7aZPmTJFbm5uF31atDNuvfVWZWRkaM6cOda0s2fP6pVXXpGfn586dOjgdJs1atTQ4MGDtXTpUr3yyiuF5ufn52vSpElOn0UtKEzPPct27NgxzZw5s8Tb6Nq1qypVqqQJEybozJkzdvPOXbZixYoOL9++55579Ntvv+k///lPoXmnT5/WyZMni93nc/n6+uqJJ57Q999/ryeeeMLhGcf3339fGzZskPTX57thwwalpaVZ80+ePKk333xTtWrVsu6TLygyV69ebcXl5eXpzTffvKR+Shfe37Oysgrdq9ykSRO5u7sXGs7LVZT0fnM5nPl+eXh4qGvXrvr000/tbt3JzMzU7Nmz1bZtW+uyekeK+7MNAK52nFkHcE344osvtHPnTp09e1aZmZlavny5UlNTFRERoc8++6zQQ5nONW7cOK1evVrx8fGKiIjQwYMH9dprr6l69erWA7Rq166twMBAzZgxQ5UqVVLFihUVHR1d7HuCzxccHKy2bdtqwIAByszM1NSpU1WnTh274eUGDRqkefPmqVu3brrnnnu0Z88evf/++3YPSnK2b7fffrs6deqkf/3rX9q3b5+aNWumpUuX6tNPP9WwYcMKtX2phgwZojfeeEP9+/dXenq6atWqpXnz5mnNmjWaOnWq0w+JKzBp0iTt2bNHjzzyiP73v//ptttuU1BQkPbv36+5c+dq586d6tOnj1Ntdu3aVTabTbfffrv+/ve/68SJE/rPf/6jqlWr6sCBAyXahr+/v6ZMmaJBgwapVatWuvfeexUUFKRvv/1Wp06dssahj4qK0pw5c5ScnKxWrVrJz89Pt99+ux544AF9/PHHeuihh7RixQrdfPPNysvL086dO/Xxxx9b479fihEjRmj79u2aNGmSVqxYobvuukthYWHKyMjQ/PnztWHDBq1du1aS9OSTT+rDDz9U9+7d9cgjjyg4OFizZs3S3r179d///te6mqJRo0Zq06aNRo4cqcOHDys4OFgfffRRoaLaGRfa37/99lslJSXp7rvv1g033KCzZ8/qvffek4eHh3r16nXJ67scX331VaHiWvrrAWdNmzYt8f3mcjnz/Xr22WeVmpqqtm3b6h//+IcqVKigN954Q9nZ2UWO617cn20AcNUr+wfQA0DZKRgaquBls9lMWFiYueWWW8y0adPshggrcP7QbcuWLTN33HGHCQ8PNzabzYSHh5u+ffuaH374wW65Tz/91DRs2NBUqFDBbuioDh06mEaNGjns34WGIvrwww/NyJEjTdWqVY2Pj4+Jj483P//8c6HlJ02aZK677jrj5eVlbr75ZrNx48ZCbV6sb+cPSWXMX0NsDR8+3ISHhxtPT09Tt25d8+KLL9oNAWXMX0MeJSYmFurThYZdOl9mZqYZMGCAqVKlirHZbKZJkyYOh5cr7tBtBc6ePWveeust065dOxMQEGA8PT1NRESEGTBggN2wUwWf8/lD8jkaTuyzzz4zTZs2Nd7e3qZWrVrmhRdeMO+8806huIv1tbhtFMTedNNNxsfHx/j7+5vWrVubDz/80Jp/4sQJc++995rAwEAjye4zzMnJMS+88IJp1KiR8fLyMkFBQSYqKsqMHTvWHDt2zIq70OdXlHnz5pmuXbua4OBgU6FCBVOtWjXTu3dvs3LlSru4PXv2mLvuussEBgYab29v07p1a7NgwYJC7e3Zs8fExsYaLy8vExoaap566imTmprqcOg2R98jR/uwo/39p59+MgMHDjS1a9c23t7eJjg42HTq1Ml8+eWXRW7zhYZue/HFFwvFSjKjR4++aHtFDd127vIlud84k8MLKe73yxhjNm3aZOLi4oyfn5/x9fU1nTp1MmvXrnWYi3M/a2OK97OtYNnzh+O70JCdjr7zl/tzDABKk5sxPD0DAAAAAABXwj3rAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAAAAAHAxFOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAAAAAHAxFOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHbgEHTt2VOPGjcu7G1elffv2yc3NTSkpKeXdlXLRsWNHdezYsby7AQC4AnA8Unqu9eMRuAaKdeAa89xzz2n+/Pnl3Y1ys2PHDo0ZM0b79u27pvsAAEB5utaPR5x16tQpjRkzRitXrizvrqAMUawD1xhX/+UYERGh06dP64EHHiiV9nfs2KGxY8eWe7F+oT4sXbpUS5cuLftOAQBQhq714xFnnTp1SmPHjqVYv8ZQrAMu6uzZs8rJySnvbhTLmTNnlJ+fXyJtubm5ydvbWx4eHiXS3uUwxuj06dNluk6bzSabzVam6wQA4EI4Hin/4xFcuyjWUarGjBkjNzc37d69W/3791dgYKACAgI0YMAAnTp1StLF7wlyc3PTmDFjCrX3ww8/6P7771dAQIBCQkL0zDPPyBijX375RXfccYf8/f0VFhamSZMmXVK/v/jiC3Xo0EGVKlWSv7+/WrVqpdmzZxeK27Fjhzp16iRfX19dd911mjhxot38nJwcjRo1SlFRUQoICFDFihXVrl07rVixwi6uIAcvvfSSpk6dqtq1a8vLy0s7duwodhuSlJ+fr2nTpqlJkyby9vZWSEiIunXrpo0bN1r5PHnypGbNmiU3Nze5ubmpf//+1vK//fabBg4cqNDQUHl5ealRo0Z655137NaxcuVKubm56aOPPtLTTz+t6667Tr6+vsrKylJubq7Gjh2runXrytvbW5UrV1bbtm2Vmppa7Nw72h/69+8vPz8//fbbb+rRo4f8/PwUEhKixx57THl5eXbLf/TRR4qKirI+uyZNmmjatGmSpJSUFN19992SpE6dOlk5KPgrda1atXTbbbdpyZIlatmypXx8fPTGG284tY8W5DEhIUHh4eHy8vJSZGSkhg4dqpycnCL74Oie9YMHDyohIUGhoaHy9vZWs2bNNGvWLId5e+mll/Tmm29a+1CrVq30zTffFDv/AHA14niE45GyPB45N49TpkxRRESEfHx81KFDB23bts1uPRd6Vk3//v1Vq1Ytq72QkBBJ0tixY62cnX/8gatPhfLuAK4N99xzjyIjIzVhwgRt2rRJb731lqpWraoXXnjhktrr3bu3GjRooOeff14LFy7Us88+q+DgYL3xxhvq3LmzXnjhBX3wwQd67LHH1KpVK7Vv377YbaekpGjgwIFq1KiRRo4cqcDAQG3evFmLFy/Wvffea8UdOXJE3bp1U8+ePXXPPfdo3rx5euKJJ9SkSRN1795dkpSVlaW33npLffv21eDBg3X8+HG9/fbbiouL04YNG9S8eXO7dc+cOVNnzpzRkCFD5OXlpeDgYKfaSEhIUEpKirp3765Bgwbp7Nmz+uqrr7Ru3Tq1bNlS7733ngYNGqTWrVtryJAhkqTatWtLkjIzM9WmTRu5ubkpKSlJISEh+uKLL5SQkKCsrCwNGzbMrq/jx4+XzWbTY489puzsbNlsNo0ZM0YTJkyw1pGVlaWNGzdq06ZNuuWWW5z4hAvLy8tTXFycoqOj9dJLL+nLL7/UpEmTVLt2bQ0dOlSSlJqaqr59+6pLly7WvvX9999rzZo1evTRR9W+fXs98sgjevnll/XUU0+pQYMGkmT9K0m7du1S37599fe//12DBw9WvXr1nOrn77//rtatW+vo0aMaMmSI6tevr99++03z5s3TqVOnitWHc50+fVodO3bU7t27lZSUpMjISM2dO1f9+/fX0aNH9eijj9rFz549W8ePH9ff//53ubm5aeLEierZs6d++ukneXp6OrUtAHC14XiE45GyOB4p8O677+r48eNKTEzUmTNnNG3aNHXu3Flbt25VaGhosdcZEhKi119/XUOHDtWdd96pnj17SpKaNm16WduCK4ABStHo0aONJDNw4EC76XfeeaepXLmyMcaYvXv3Gklm5syZhZaXZEaPHl2ovSFDhljTzp49a6pXr27c3NzM888/b00/cuSI8fHxMf369St2f48ePWoqVapkoqOjzenTp+3m5efnW//v0KGDkWTeffdda1p2drYJCwszvXr1sutbdna2XTtHjhwxoaGhdjkpyIG/v785ePCgXXxx21i+fLmRZB555JFC23Vu3ytWrOgwJwkJCaZatWrmjz/+sJvep08fExAQYE6dOmWMMWbFihVGkrn++uutaQWaNWtm4uPjC7XtDEf7Q79+/YwkM27cOLvYFi1amKioKOv9o48+avz9/c3Zs2cv2P7cuXONJLNixYpC8yIiIowks3jx4iL7VOD8ffTBBx807u7u5ptvvikUW/A5XKwPHTp0MB06dLDeT5061Ugy77//vjUtJyfHxMTEGD8/P5OVlWXXx8qVK5vDhw9bsZ9++qmRZD7//HNH6QCAawLHIxyPOOtyjkcKlvXx8TG//vqrNX39+vVGkhk+fLg17fzf++euKyIiwnp/6NChQvshrn5cBo8y8dBDD9m9b9eunf78809lZWVdUnuDBg2y/u/h4aGWLVvKGKOEhARremBgoOrVq6effvqp2O2mpqbq+PHjevLJJ+Xt7W03z83Nze69n5+f7r//fuu9zWZT69at7dbn4eFh3X+cn5+vw4cP6+zZs2rZsqU2bdpUaP29evWyLnNyto3//ve/cnNz0+jRowu1e37fz2eM0X//+1/dfvvtMsbojz/+sF5xcXE6duxYof7269dPPj4+dtMCAwO1fft2/fjjjxdd36VytB+dm+/AwECdPHnSqcvczhcZGam4uLhLWjY/P1/z58/X7bffrpYtWxaaX9Tn4MiiRYsUFhamvn37WtM8PT31yCOP6MSJE1q1apVdfO/evRUUFGS9b9eunSQ59T0AgKsVxyMcj5SEoo5HCvTo0UPXXXed9b5169aKjo7WokWLSqVfuPpQrKNM1KxZ0+59QTFx5MiREmkvICBA3t7eqlKlSqHpzqxjz549klSsMUurV69e6JdOUFBQofXNmjVLTZs2te6ZCgkJ0cKFC3Xs2LFCbUZGRjpcV3Ha2LNnj8LDwxUcHFxk38936NAhHT16VG+++aZCQkLsXgMGDJD0133TRfV13LhxOnr0qG644QY1adJEI0aM0Hfffed0fxwpuOftXOfn+x//+IduuOEGde/eXdWrV9fAgQO1ePFip9Zzoc+gOA4dOqSsrKwSHfP2559/Vt26deXubv/juuCy+Z9//tluekl/1wDgasLxCMcjl6s4xyMF6tatW2jaDTfcwNCtKDbuWUeZuNCTNI0xF/wr6/kPDiuqvYutozQUZ33vv/+++vfvrx49emjEiBGqWrWqPDw8NGHCBOsX8bnO/8vwpbRxKQqenHr//ferX79+DmPOvy/KUV/bt2+vPXv26NNPP9XSpUv11ltvacqUKZoxY4bd2YdLUZynsVatWlVbtmzRkiVL9MUXX+iLL77QzJkz9eCDDxZ6INuFONquS9lHy0tZfw8A4ErC8QjHI2VxPOIMNzc3h/uGKx5joOxRrKPcFfxV++jRo3bTzz9jWBYKHm6ybds21alT57Lbmzdvnq6//nr973//szsIcHRp2OW2Ubt2bS1ZskSHDx++6F+zHR2MhISEqFKlSsrLy1NsbGyx++ZIcHCwBgwYoAEDBujEiRNq3769xowZc9m/HIvLZrPp9ttv1+233678/Hz94x//0BtvvKFnnnlGderUuaRL0Yu7j4aEhMjf37/Qk17P50wfIiIi9N133yk/P9/u7PrOnTut+QCAy8fxSMm0wfHI/3F0Gf4PP/xgPeVd+mu/c3QJ/fn73aUcv+DKx2XwKHf+/v6qUqWKVq9ebTf9tddeK/O+dO3aVZUqVdKECRN05swZu3mX8hfxgr++nrvs+vXrlZaWVuJt9OrVS8YYjR07tlAb5y5bsWLFQgciHh4e6tWrl/773/86LDQPHTpUrL7++eefdu/9/PxUp04dZWdnF2v5y3X++t3d3a2/wBf0oWLFipIKH4xdTHH3UXd3d/Xo0UOff/65NTzNuQo+B2f6cOuttyojI0Nz5syxpp09e1avvPKK/Pz81KFDh2JvBwDgwjgeKZk2OB75P/Pnz9dvv/1mvd+wYYPWr19vPaVf+uuPGzt37rTbtm+//VZr1qyxa8vX11eSc8cvuPJxZh0uYdCgQXr++ec1aNAgtWzZUqtXr9YPP/xQ5v3w9/fXlClTNGjQILVq1Ur33nuvgoKC9O233+rUqVPFvpS6wG233ab//e9/uvPOOxUfH6+9e/dqxowZatiwoU6cOFGibXTq1EkPPPCAXn75Zf3444/q1q2b8vPz9dVXX6lTp05KSkqSJEVFRenLL7/U5MmTFR4ersjISEVHR+v555/XihUrFB0drcGDB6thw4Y6fPiwNm3apC+//FKHDx8usq8NGzZUx44dFRUVpeDgYG3cuFHz5s2z1l3aBg0apMOHD6tz586qXr26fv75Z73yyitq3ry5dY938+bN5eHhoRdeeEHHjh2Tl5eXOnfurKpVqxbZdnH20eeee05Lly5Vhw4dNGTIEDVo0EAHDhzQ3Llz9fXXXyswMNCpPgwZMkRvvPGG+vfvr/T0dNWqVUvz5s3TmjVrNHXqVFWqVKlkkgcA4HikBNrgeOT/1KlTR23bttXQoUOVnZ2tqVOnqnLlynr88cetmIEDB2ry5MmKi4tTQkKCDh48qBkzZqhRo0Z2Dz708fFRw4YNNWfOHN1www0KDg5W48aNS/Q5OXBBZfbceVyTCoY2OXTokN30mTNnGklm7969xhhjTp06ZRISEkxAQICpVKmSueeee8zBgwcvOFTK+e3169fPVKxYsdD6O3ToYBo1auR0vz/77DNz0003GR8fH+Pv729at25tPvzwwyLbPX+Yjfz8fPPcc8+ZiIgI4+XlZVq0aGEWLFhQKK5giI8XX3yxUJvFbcOYv4ZVefHFF039+vWNzWYzISEhpnv37iY9Pd2K2blzp2nfvr3x8fExkuyGTcnMzDSJiYmmRo0axtPT04SFhZkuXbqYN99804opGCpl7ty5hfr67LPPmtatW5vAwEDj4+Nj6tevb/7973+bnJyci6XbzoWGSnH0+RbsDwXmzZtnunbtaqpWrWpsNpupWbOm+fvf/24OHDhgt9x//vMfc/311xsPDw+7IdQiIiIuONRLcfdRY4z5+eefzYMPPmhCQkKMl5eXuf76601iYqLdkDcX6oOjIVwyMzPNgAEDTJUqVYzNZjNNmjQpNLTQxfYhR30EgGsJxyMcj5Tl8ci5eZw0aZKpUaOG8fLyMu3atTPffvttoeXff/99c/311xubzWaaN29ulixZ4jCva9euNVFRUcZms/G7/RrhZgxPHQIAAACAkrBv3z5FRkbqxRdf1GOPPVbe3cEVjHvWAQAAAABwMdyzjmvGoUOHLjoMhs1mu6QxQVE8OTk5Rd5nFhAQ4HAIFgAArhYcj5QvjkdwJaFYxzWjVatWFx1+pUOHDlq5cmXZdegas3btWnXq1OmiMTNnzlT//v3LpkMAAJQDjkfKF8cjuJJwzzquGWvWrNHp06cvOD8oKEhRUVFl2KNry5EjR5Senn7RmEaNGqlatWpl1CMAAMoexyPli+MRXEko1gEAAAAAcDHX9GXw+fn5+v3331WpUiW5ubmVd3cAAFcoY4yOHz+u8PBwubvz7NarEccMAICSUtzjhmu6WP/9999Vo0aN8u4GAOAq8csvv6h69erl3Q2UAo4ZAAAlrajjhmu6WK9UqZKkv5Lk7+9/0djc3FwtXbpUXbt2laenZ1l074pHzpxDvpxHzpxDvpxX3JxlZWWpRo0a1u8VXH2cOWYoCt9Fx8iLY+TFMfLiGHlxzNXyUtzjhmu6WC+4jM3f379Yxbqvr6/8/f1d4gO+EpAz55Av55Ez55Av5zmbMy6Pvno5c8xQFL6LjpEXx8iLY+TFMfLimKvmpajjBm6sAwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKpR3B1A8tZ5c6PQy+56PL4WeAACAktB4zBJl57kVK5bf6QBw7eHMOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAAAAAHAxFOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAJSa3377Tffff78qV64sHx8fNWnSRBs3brTmG2M0atQoVatWTT4+PoqNjdWPP/5o18bhw4d13333yd/fX4GBgUpISNCJEyfsYr777ju1a9dO3t7eqlGjhiZOnFioL3PnzlX9+vXl7e2tJk2aaNGiRaWz0QAAlACKdQAAUCqOHDmim2++WZ6envriiy+0Y8cOTZo0SUFBQVbMxIkT9fLLL2vGjBlav369KlasqLi4OJ05c8aKue+++7R9+3alpqZqwYIFWr16tYYMGWLNz8rKUteuXRUREaH09HS9+OKLGjNmjN58800rZu3aterbt68SEhK0efNm9ejRQz169NC2bdvKJhkAADipQnl3AAAAXJ1eeOEF1ahRQzNnzrSmRUZGWv83xmjq1Kl6+umndccdd0iS3n33XYWGhmr+/Pnq06ePvv/+ey1evFjffPONWrZsKUl65ZVXdOutt+qll15SeHi4PvjgA+Xk5Oidd96RzWZTo0aNtGXLFk2ePNkq6qdNm6Zu3bppxIgRkqTx48crNTVVr776qmbMmFFWKQEAoNgo1gEAQKn47LPPFBcXp7vvvlurVq3Sddddp3/84x8aPHiwJGnv3r3KyMhQbGystUxAQICio6OVlpamPn36KC0tTYGBgVahLkmxsbFyd3fX+vXrdeeddyotLU3t27eXzWazYuLi4vTCCy/oyJEjCgoKUlpampKTk+36FxcXp/nz5zvse3Z2trKzs633WVlZkqTc3Fzl5uZeVl4KlvdyN04vczUr2MZrYVudQV4cIy+OkRfHXC0vxe0HxToAACgVP/30k15//XUlJyfrqaee0jfffKNHHnlENptN/fr1U0ZGhiQpNDTUbrnQ0FBrXkZGhqpWrWo3v0KFCgoODraLOfeM/bltZmRkKCgoSBkZGRddz/kmTJigsWPHFpq+dOlS+fr6FjcFFzW+ZX6xY6+l++tTU1PLuwsuibw4Rl4cIy+OuUpeTp06Vaw4inUAAFAq8vPz1bJlSz333HOSpBYtWmjbtm2aMWOG+vXrV869u7iRI0fanYnPyspSjRo11LVrV/n7+19W27m5uUpNTdUzG92Vne9WrGW2jYm7rHVeCQrycsstt8jT07O8u+MyyItj5MUx8uKYq+Wl4GqtolCsAwCAUlGtWjU1bNjQblqDBg303//+V5IUFhYmScrMzFS1atWsmMzMTDVv3tyKOXjwoF0bZ8+e1eHDh63lw8LClJmZaRdT8L6omIL55/Py8pKXl1eh6Z6eniV2oJed76bsvOIV665wcFlWSjLHVxPy4hh5cYy8OOYqeSluH3gaPAAAKBU333yzdu3aZTfthx9+UEREhKS/HjYXFhamZcuWWfOzsrK0fv16xcTESJJiYmJ09OhRpaenWzHLly9Xfn6+oqOjrZjVq1fb3QOYmpqqevXqWU+ej4mJsVtPQUzBegAAcDVOFesTJkxQq1atVKlSJVWtWlU9evQo9Ev4zJkzSkxMVOXKleXn56devXoV+kv2/v37FR8fL19fX1WtWlUjRozQ2bNn7WJWrlypG2+8UV5eXqpTp45SUlIK9Wf69OmqVauWvL29FR0drQ0bNjizOQAAoBQNHz5c69at03PPPafdu3dr9uzZevPNN5WYmChJcnNz07Bhw/Tss8/qs88+09atW/Xggw8qPDxcPXr0kPTXmfhu3bpp8ODB2rBhg9asWaOkpCT16dNH4eHhkqR7771XNptNCQkJ2r59u+bMmaNp06bZXcb+6KOPavHixZo0aZJ27typMWPGaOPGjUpKSirzvAAAUBxOFeurVq1SYmKi1q1bp9TUVOXm5qpr1646efKkFTN8+HB9/vnnmjt3rlatWqXff/9dPXv2tObn5eUpPj5eOTk5Wrt2rWbNmqWUlBSNGjXKitm7d6/i4+PVqVMnbdmyRcOGDdOgQYO0ZMkSK2bOnDlKTk7W6NGjtWnTJjVr1kxxcXGFLpUDAADlo1WrVvrkk0/04YcfqnHjxho/frymTp2q++67z4p5/PHH9fDDD2vIkCFq1aqVTpw4ocWLF8vb29uK+eCDD1S/fn116dJFt956q9q2bWs3hnpAQICWLl2qvXv3KioqSv/85z81atQou7HYb7rpJuuPBc2aNdO8efM0f/58NW7cuGySAQCAk5y6Z33x4sV271NSUlS1alWlp6erffv2OnbsmN5++23Nnj1bnTt3liTNnDlTDRo00Lp169SmTRstXbpUO3bs0JdffqnQ0FA1b95c48eP1xNPPKExY8bIZrNpxowZioyM1KRJkyT99Vf1r7/+WlOmTFFc3F8PWJk8ebIGDx6sAQMGSJJmzJihhQsX6p133tGTTz552YkBAACX77bbbtNtt912wflubm4aN26cxo0bd8GY4OBgzZ49+6Lradq0qb766quLxtx99926++67L95hAABcxGU9YO7YsWOS/volKknp6enKzc21Gy+1fv36qlmzptLS0tSmTRulpaWpSZMmdsOnxMXFaejQodq+fbtatGihtLQ0uzYKYoYNGyZJysnJUXp6ukaOHGnNd3d3V2xsrNLS0i7Y38sZM7W8x+bz8ij+WKwFynscwfLO2ZWGfDmPnDmHfDmvuDkjpwAAoKRdcrGen5+vYcOG6eabb7YuIcvIyJDNZlNgYKBd7PnjpToa57Rg3sVisrKydPr0aR05ckR5eXkOY3bu3HnBPpfEmKnlNTbfxNbOL+MqY7K6yniGVwry5Txy5hzy5byiclbc8VIBAACK65KL9cTERG3btk1ff/11SfanVF3OmKnlPTZf4zFLig46T3mPyVreObvSkC/nkTPnkC/nFTdnxR0vFQAAoLguqVhPSkrSggULtHr1alWvXt2aHhYWppycHB09etTu7Pq545iGhYUVemp7ccdC9ff3l4+Pjzw8POTh4eHUeKlSyYyZWl5j8xV3HNZzucrBuKuMZ3ilIF/OI2fOIV/OKypn5BMAAJQ0p4p1Y4wefvhhffLJJ1q5cqUiIyPt5kdFRcnT01PLli1Tr169JEm7du3S/v377cZL/fe//62DBw+qatWqkv66vNDf318NGza0Ys6/hPvcsVBtNpuioqK0bNkya2iX/Px8LVu2jCFYzlHryYVOxe97Pr6UegIAAAAAcIZTxXpiYqJmz56tTz/9VJUqVbLuMQ8ICJCPj48CAgKUkJCg5ORkBQcHy9/fXw8//LBiYmLUpk0bSVLXrl3VsGFDPfDAA5o4caIyMjL09NNPKzEx0Trr/dBDD+nVV1/V448/roEDB2r58uX6+OOPtXDh/xWfycnJ6tevn1q2bKnWrVtr6tSpOnnypPV0eAAAAAAArlROFeuvv/66JKljx45202fOnKn+/ftLkqZMmSJ3d3f16tVL2dnZiouL02uvvWbFenh4aMGCBRo6dKhiYmJUsWJF9evXz27IlsjISC1cuFDDhw/XtGnTVL16db311lvWsG2S1Lt3bx06dEijRo1SRkaGmjdvrsWLFxd66BwAAAAAAFcapy+DL4q3t7emT5+u6dOnXzAmIiKiyCeVd+zYUZs3b75oTFJSEpe9AwAAAACuOu7l3QEAAAAAAGCPYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAIBSMWbMGLm5udm96tevb80/c+aMEhMTVblyZfn5+alXr17KzMy0a2P//v2Kj4+Xr6+vqlatqhEjRujs2bN2MStXrtSNN94oLy8v1alTRykpKYX6Mn36dNWqVUve3t6Kjo7Whg0bSmWbAQAoKRTrAACg1DRq1EgHDhywXl9//bU1b/jw4fr88881d+5crVq1Sr///rt69uxpzc/Ly1N8fLxycnK0du1azZo1SykpKRo1apQVs3fvXsXHx6tTp07asmWLhg0bpkGDBmnJkiVWzJw5c5ScnKzRo0dr06ZNatasmeLi4nTw4MGySQIAAJeAYh0AAJSaChUqKCwszHpVqVJFknTs2DG9/fbbmjx5sjp37qyoqCjNnDlTa9eu1bp16yRJS5cu1Y4dO/T++++refPm6t69u8aPH6/p06crJydHkjRjxgxFRkZq0qRJatCggZKSknTXXXdpypQpVh8mT56swYMHa8CAAWrYsKFmzJghX19fvfPOO2WfEAAAiqlCeXcAAABcvX788UeFh4fL29tbMTExmjBhgmrWrKn09HTl5uYqNjbWiq1fv75q1qyptLQ0tWnTRmlpaWrSpIlCQ0OtmLi4OA0dOlTbt29XixYtlJaWZtdGQcywYcMkSTk5OUpPT9fIkSOt+e7u7oqNjVVaWtoF+52dna3s7GzrfVZWliQpNzdXubm5l5WTguW93I3Ty1zNCrbxWthWZ5AXx8iLY+TFMVfLS3H7QbEOAABKRXR0tFJSUlSvXj0dOHBAY8eOVbt27bRt2zZlZGTIZrMpMDDQbpnQ0FBlZGRIkjIyMuwK9YL5BfMuFpOVlaXTp0/ryJEjysvLcxizc+fOC/Z9woQJGjt2bKHpS5cula+vb/ESUITxLfOLHbto0aISWeeVIDU1tby74JLIi2PkxTHy4pir5OXUqVPFiqNYBwAApaJ79+7W/5s2baro6GhFRETo448/lo+PTzn2rGgjR45UcnKy9T4rK0s1atRQ165d5e/vf1lt5+bmKjU1Vc9sdFd2vluxltk2Ju6y1nklKMjLLbfcIk9Pz/LujssgL46RF8fIi2OulpeCq7WKQrEOAADKRGBgoG644Qbt3r1bt9xyi3JycnT06FG7s+uZmZkKCwuTJIWFhRV6anvB0+LPjTn/CfKZmZny9/eXj4+PPDw85OHh4TCmoA1HvLy85OXlVWi6p6dniR3oZee7KTuveMW6KxxclpWSzPHVhLw4Rl4cIy+OuUpeitsHHjAHAADKxIkTJ7Rnzx5Vq1ZNUVFR8vT01LJly6z5u3bt0v79+xUTEyNJiomJ0datW+2e2p6amip/f381bNjQijm3jYKYgjZsNpuioqLsYvLz87Vs2TIrBgAAV0SxDgAASsVjjz2mVatWad++fVq7dq3uvPNOeXh4qG/fvgoICFBCQoKSk5O1YsUKpaena8CAAYqJiVGbNm0kSV27dlXDhg31wAMP6Ntvv9WSJUv09NNPKzEx0Trr/dBDD+mnn37S448/rp07d+q1117Txx9/rOHDh1v9SE5O1n/+8x/NmjVL33//vYYOHaqTJ09qwIAB5ZIXAACKg8vgAQBAqfj111/Vt29f/fnnnwoJCVHbtm21bt06hYSESJKmTJkid3d39erVS9nZ2YqLi9Nrr71mLe/h4aEFCxZo6NChiomJUcWKFdWvXz+NGzfOiomMjNTChQs1fPhwTZs2TdWrV9dbb72luLj/u8e7d+/eOnTokEaNGqWMjAw1b95cixcvLvTQOQAAXAnFOgAAKBUfffTRRed7e3tr+vTpmj59+gVjIiIiinwSeseOHbV58+aLxiQlJSkpKemiMQAAuBIugwcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAX43Sxvnr1at1+++0KDw+Xm5ub5s+fbze/f//+cnNzs3t169bNLubw4cO677775O/vr8DAQCUkJOjEiRN2Md99953atWsnb29v1ahRQxMnTizUl7lz56p+/fry9vZWkyZNtGjRImc3BwAAAAAAl+N0sX7y5Ek1a9ZM06dPv2BMt27ddODAAev14Ycf2s2/7777tH37dqWmpmrBggVavXq1hgwZYs3PyspS165dFRERofT0dL344osaM2aM3nzzTStm7dq16tu3rxISErR582b16NFDPXr00LZt25zdJAAAAAAAXEoFZxfo3r27unfvftEYLy8vhYWFOZz3/fffa/Hixfrmm2/UsmVLSdIrr7yiW2+9VS+99JLCw8P1wQcfKCcnR++8845sNpsaNWqkLVu2aPLkyVZRP23aNHXr1k0jRoyQJI0fP16pqal69dVXNWPGDIfrzs7OVnZ2tvU+KytLkpSbm6vc3NyLblPB/KLiSouXhyn1dZT0tpV3zq405Mt55Mw55Mt5xc0ZOQUAACXN6WK9OFauXKmqVasqKChInTt31rPPPqvKlStLktLS0hQYGGgV6pIUGxsrd3d3rV+/XnfeeafS0tLUvn172Ww2KyYuLk4vvPCCjhw5oqCgIKWlpSk5OdluvXFxcYUuyz/XhAkTNHbs2ELTly5dKl9f32JtW2pqarHiStrE1qW/jtK6jaC8cnalIl/OI2fOIV/OKypnp06dKqOeAACAa0WJF+vdunVTz549FRkZqT179uipp55S9+7dlZaWJg8PD2VkZKhq1ar2nahQQcHBwcrIyJAkZWRkKDIy0i4mNDTUmhcUFKSMjAxr2rkxBW04MnLkSLsCPysrSzVq1FDXrl3l7+9/0e3Kzc1VamqqbrnlFnl6ehadiBLWeMySUl/HtjFxJdpeeefsSkO+nEfOnEO+nFfcnBVcqQUAAFBSSrxY79Onj/X/Jk2aqGnTpqpdu7ZWrlypLl26lPTqnOLl5SUvL69C0z09PYt94OpMbEnKznMr9XWU1naVV86uVOTLeeTMOeTLeUXljHwCAICSVupDt11//fWqUqWKdu/eLUkKCwvTwYMH7WLOnj2rw4cPW/e5h4WFKTMz0y6m4H1RMRe6Vx4AAAAAgCtFqRfrv/76q/78809Vq1ZNkhQTE6OjR48qPT3dilm+fLny8/MVHR1txaxevdrugT2pqamqV6+egoKCrJhly5bZrSs1NVUxMTGlvUkAAAAAAJQqp4v1EydOaMuWLdqyZYskae/evdqyZYv279+vEydOaMSIEVq3bp327dunZcuW6Y477lCdOnUUF/fX/dANGjRQt27dNHjwYG3YsEFr1qxRUlKS+vTpo/DwcEnSvffeK5vNpoSEBG3fvl1z5szRtGnT7O43f/TRR7V48WJNmjRJO3fu1JgxY7Rx40YlJSWVQFoAAAAAACg/ThfrGzduVIsWLdSiRQtJUnJyslq0aKFRo0bJw8ND3333nf72t7/phhtuUEJCgqKiovTVV1/Z3Sv+wQcfqH79+urSpYtuvfVWtW3b1m4M9YCAAC1dulR79+5VVFSU/vnPf2rUqFF2Y7HfdNNNmj17tt588001a9ZM8+bN0/z589W4cePLyQcAAAAAAOXO6QfMdezYUcZceMzvJUuKfmp5cHCwZs+efdGYpk2b6quvvrpozN1336277767yPUBAAAAAHAlKfV71gEAAAAAgHMo1gEAAAAAcDEU6wAAoNQ9//zzcnNz07Bhw6xpZ86cUWJioipXriw/Pz/16tWr0LCs+/fvV3x8vHx9fVW1alWNGDFCZ8+etYtZuXKlbrzxRnl5ealOnTpKSUkptP7p06erVq1a8vb2VnR0tDZs2FAamwkAQImhWAcAAKXqm2++0RtvvKGmTZvaTR8+fLg+//xzzZ07V6tWrdLvv/+unj17WvPz8vIUHx+vnJwcrV27VrNmzVJKSopGjRplxezdu1fx8fHq1KmTtmzZomHDhmnQoEF2z9CZM2eOkpOTNXr0aG3atEnNmjVTXFycDh48WPobDwDAJaJYBwAApebEiRO677779J///EdBQUHW9GPHjuntt9/W5MmT1blzZ0VFRWnmzJlau3at1q1bJ0launSpduzYoffff1/NmzdX9+7dNX78eE2fPl05OTmSpBkzZigyMlKTJk1SgwYNlJSUpLvuuktTpkyx1jV58mQNHjxYAwYMUMOGDTVjxgz5+vrqnXfeKdtkAADgBKefBg8AAFBciYmJio+PV2xsrJ599llrenp6unJzcxUbG2tNq1+/vmrWrKm0tDS1adNGaWlpatKkiUJDQ62YuLg4DR06VNu3b1eLFi2UlpZm10ZBTMHl9jk5OUpPT9fIkSOt+e7u7oqNjVVaWtoF+52dna3s7GzrfVZWliQpNzdXubm5l5aM/69geS/3C4+uc6FlrmYF23gtbKszyItj5MUx8uKYq+WluP2gWAcAAKXio48+0qZNm/TNN98UmpeRkSGbzabAwEC76aGhocrIyLBizi3UC+YXzLtYTFZWlk6fPq0jR44oLy/PYczOnTsv2PcJEyZo7NixhaYvXbpUvr6+F1zOGeNb5hc7dtGiRSWyzitBampqeXfBJZEXx8iLY+TFMVfJy6lTp4oVR7EOAABK3C+//KJHH31Uqamp8vb2Lu/uOG3kyJFKTk623mdlZalGjRrq2rWr/P39L6vt3Nxcpaam6pmN7srOdyvWMtvGxF3WOq8EBXm55ZZb5OnpWd7dcRnkxTHy4hh5cczV8lJwtVZRKNYBAECJS09P18GDB3XjjTda0/Ly8rR69Wq9+uqrWrJkiXJycnT06FG7s+uZmZkKCwuTJIWFhRV6anvB0+LPjTn/CfKZmZny9/eXj4+PPDw85OHh4TCmoA1HvLy85OXlVWi6p6dniR3oZee7KTuveMW6KxxclpWSzPHVhLw4Rl4cIy+OuUpeitsHHjAHAABKXJcuXbR161Zt2bLFerVs2VL33Xef9X9PT08tW7bMWmbXrl3av3+/YmJiJEkxMTHaunWr3VPbU1NT5e/vr4YNG1ox57ZREFPQhs1mU1RUlF1Mfn6+li1bZsUAAOCKOLMOAABKXKVKldS4cWO7aRUrVlTlypWt6QkJCUpOTlZwcLD8/f318MMPKyYmRm3atJEkde3aVQ0bNtQDDzygiRMnKiMjQ08//bQSExOts94PPfSQXn31VT3++OMaOHCgli9fro8//lgLFy601pucnKx+/fqpZcuWat26taZOnaqTJ09qwIABZZQNAACcR7EOAADKxZQpU+Tu7q5evXopOztbcXFxeu2116z5Hh4eWrBggYYOHaqYmBhVrFhR/fr107hx46yYyMhILVy4UMOHD9e0adNUvXp1vfXWW4qL+797vHv37q1Dhw5p1KhRysjIUPPmzbV48eJCD50DAMCVUKwDAIAysXLlSrv33t7emj59uqZPn37BZSIiIop8EnrHjh21efPmi8YkJSUpKSmp2H0FAKC8cc86AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAAAAAHAxFOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAIBS8frrr6tp06by9/eXv7+/YmJi9MUXX1jzz5w5o8TERFWuXFl+fn7q1auXMjMz7drYv3+/4uPj5evrq6pVq2rEiBE6e/asXczKlSt14403ysvLS3Xq1FFKSkqhvkyfPl21atWSt7e3oqOjtWHDhlLZZgAASgrFOgAAKBXVq1fX888/r/T0dG3cuFGdO3fWHXfcoe3bt0uShg8frs8//1xz587VqlWr9Pvvv6tnz57W8nl5eYqPj1dOTo7Wrl2rWbNmKSUlRaNGjbJi9u7dq/j4eHXq1ElbtmzRsGHDNGjQIC1ZssSKmTNnjpKTkzV69Ght2rRJzZo1U1xcnA4ePFh2yQAAwEkU6wAAoFTcfvvtuvXWW1W3bl3dcMMN+ve//y0/Pz+tW7dOx44d09tvv63Jkyerc+fOioqK0syZM7V27VqtW7dOkrR06VLt2LFD77//vpo3b67u3btr/Pjxmj59unJyciRJM2bMUGRkpCZNmqQGDRooKSlJd911l6ZMmWL1Y/LkyRo8eLAGDBighg0basaMGfL19dU777xTLnkBAKA4KpR3BwAAwNUvLy9Pc+fO1cmTJxUTE6P09HTl5uYqNjbWiqlfv75q1qyptLQ0tWnTRmlpaWrSpIlCQ0OtmLi4OA0dOlTbt29XixYtlJaWZtdGQcywYcMkSTk5OUpPT9fIkSOt+e7u7oqNjVVaWtoF+5udna3s7GzrfVZWliQpNzdXubm5l5WLguW93I3Ty1zNCrbxWthWZ5AXx8iLY+TFMVfLS3H74XSxvnr1ar344otKT0/XgQMH9Mknn6hHjx7WfGOMRo8erf/85z86evSobr75Zr3++uuqW7euFXP48GE9/PDD+vzzz+Xu7q5evXpp2rRp8vPzs2K+++47JSYm6ptvvlFISIgefvhhPf7443Z9mTt3rp555hnt27dPdevW1QsvvKBbb73V2U0CAAClZOvWrYqJidGZM2fk5+enTz75RA0bNtSWLVtks9kUGBhoFx8aGqqMjAxJUkZGhl2hXjC/YN7FYrKysnT69GkdOXJEeXl5DmN27tx5wX5PmDBBY8eOLTR96dKl8vX1Ld7GF2F8y/xixy5atKhE1nklSE1NLe8uuCTy4hh5cYy8OOYqeTl16lSx4pwu1k+ePKlmzZpp4MCBdveVFZg4caJefvllzZo1S5GRkXrmmWcUFxenHTt2yNvbW5J033336cCBA0pNTVVubq4GDBigIUOGaPbs2ZL++ut1165dFRsbqxkzZmjr1q0aOHCgAgMDNWTIEEnS2rVr1bdvX02YMEG33XabZs+erR49emjTpk1q3Lixs5sFAABKQb169bRlyxYdO3ZM8+bNU79+/bRq1ary7laRRo4cqeTkZOt9VlaWatSooa5du8rf3/+y2s7NzVVqaqqe2eiu7Hy3Yi2zbUzcZa3zSlCQl1tuuUWenp7l3R2XQV4cIy+OkRfHXC0vBVdrFcXpYr179+7q3r27w3nGGE2dOlVPP/207rjjDknSu+++q9DQUM2fP199+vTR999/r8WLF+ubb75Ry5YtJUmvvPKKbr31Vr300ksKDw/XBx98oJycHL3zzjuy2Wxq1KiRtmzZosmTJ1vF+rRp09StWzeNGDFCkjR+/Hilpqbq1Vdf1YwZM5zdLAAAUApsNpvq1KkjSYqKitI333yjadOmqXfv3srJydHRo0ftzq5nZmYqLCxMkhQWFlboqe0FT4s/N+b8J8hnZmbK399fPj4+8vDwkIeHh8OYgjYc8fLykpeXV6Hpnp6eJXagl53vpuy84hXrrnBwWVZKMsdXE/LiGHlxjLw45ip5KW4fSvSe9b179yojI8Pu3rGAgABFR0crLS1Nffr0UVpamgIDA61CXZJiY2Pl7u6u9evX684771RaWprat28vm81mxcTFxemFF17QkSNHFBQUpLS0NLu/eBfEzJ8//4L9u5z7z8r7Pgcvj+Lf13apSnrbyjtnVxry5Txy5hzy5bzi5oycFl9+fr6ys7MVFRUlT09PLVu2TL169ZIk7dq1S/v371dMTIwkKSYmRv/+97918OBBVa1aVdJflzD6+/urYcOGVsz5l4inpqZabdhsNkVFRWnZsmXWbXv5+flatmyZkpKSymKTAQC4JCVarBfcP+bovrBz7y0r+IVrdaJCBQUHB9vFREZGFmqjYF5QUNAF71EraMORkrj/rLzuc5jYuvTXUVr3w7nKvSFXCvLlPHLmHPLlvKJyVtx7z641I0eOVPfu3VWzZk0dP35cs2fP1sqVK7VkyRIFBAQoISFBycnJCg4Olr+/vx5++GHFxMSoTZs2kqSuXbuqYcOGeuCBBzRx4kRlZGTo6aefVmJionXW+6GHHtKrr76qxx9/XAMHDtTy5cv18ccfa+HChVY/kpOT1a9fP7Vs2VKtW7fW1KlTdfLkSQ0YMKBc8gIAQHFcU0+Dv5z7z8r7PofGY5YUHVTGirp/rrxzdqUhX84jZ84hX84rbs6Ke+/ZtebgwYN68MEHdeDAAQUEBKhp06ZasmSJbrnlFknSlClTrAfNZmdnKy4uTq+99pq1vIeHhxYsWKChQ4cqJiZGFStWVL9+/TRu3DgrJjIyUgsXLtTw4cM1bdo0Va9eXW+99Zbi4v7vd1Tv3r116NAhjRo1ShkZGWrevLkWL15c6I/+AAC4khIt1gvu/crMzFS1atWs6ZmZmWrevLkVc/DgQbvlzp49q8OHDxd5/9m567hQTGnff1Ze9zkU9562suTqObtSkS/nkTPnkC/nFZUz8unY22+/fdH53t7emj59uqZPn37BmIiIiCKv/OrYsaM2b9580ZikpCQuewcAXFHcS7KxyMhIhYWFadmyZda0rKwsrV+/3u7+s6NHjyo9Pd2KWb58ufLz8xUdHW3FrF692u4ewNTUVNWrV09BQUFWzLnrKYgpWA8AAAAAAFcqp4v1EydOaMuWLdqyZYukvx4qt2XLFu3fv19ubm4aNmyYnn32WX322WfaunWrHnzwQYWHh1sPdWnQoIG6deumwYMHa8OGDVqzZo2SkpLUp08fhYeHS5Luvfde2Ww2JSQkaPv27ZozZ46mTZtmdwn7o48+qsWLF2vSpEnauXOnxowZo40bN/JXcwAAAADAFc/py+A3btyoTp06We8LCuh+/fopJSVFjz/+uE6ePKkhQ4bo6NGjatu2rRYvXmyNsS5JH3zwgZKSktSlSxfrXrWXX37Zmh8QEKClS5cqMTFRUVFRqlKlikaNGmUN2yZJN910k2bPnq2nn35aTz31lOrWrav58+dfMWOs13pyYdFBAAAAAIBrktPFeseOHWXMhYcRc3Nz07hx4+we/nK+4OBgzZ49+6Lradq0qb766quLxtx99926++67L95hAAAAAACuMCV6zzoAAAAAALh8FOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAECpmDBhglq1aqVKlSqpatWq6tGjh3bt2mUXc+bMGSUmJqpy5cry8/NTr169lJmZaRezf/9+xcfHy9fXV1WrVtWIESN09uxZu5iVK1fqxhtvlJeXl+rUqaOUlJRC/Zk+fbpq1aolb29vRUdHa8OGDSW+zQAAlBSKdQAAUCpWrVqlxMRErVu3TqmpqcrNzVXXrl118uRJK2b48OH6/PPPNXfuXK1atUq///67evbsac3Py8tTfHy8cnJytHbtWs2aNUspKSkaNWqUFbN3717Fx8erU6dO2rJli4YNG6ZBgwZpyZIlVsycOXOUnJys0aNHa9OmTWrWrJni4uJ08ODBskkGAABOqlDeHQAAAFenxYsX271PSUlR1apVlZ6ervbt2+vYsWN6++23NXv2bHXu3FmSNHPmTDVo0EDr1q1TmzZttHTpUu3YsUNffvmlQkND1bx5c40fP15PPPGExowZI5vNphkzZigyMlKTJk2SJDVo0EBff/21pkyZori4OEnS5MmTNXjwYA0YMECSNGPGDC1cuFDvvPOOnnzyyUJ9z87OVnZ2tvU+KytLkpSbm6vc3NzLykvB8l7uxullrmYF23gtbKszyItj5MUx8uKYq+WluP2gWAcAAGXi2LFjkqTg4GBJUnp6unJzcxUbG2vF1K9fXzVr1lRaWpratGmjtLQ0NWnSRKGhoVZMXFychg4dqu3bt6tFixZKS0uza6MgZtiwYZKknJwcpaena+TIkdZ8d3d3xcbGKi0tzWFfJ0yYoLFjxxaavnTpUvn6+l5aAs4zvmV+sWMXLVpUIuu8EqSmppZ3F1wSeXGMvDhGXhxzlbycOnWqWHEU6wAAoNTl5+dr2LBhuvnmm9W4cWNJUkZGhmw2mwIDA+1iQ0NDlZGRYcWcW6gXzC+Yd7GYrKwsnT59WkeOHFFeXp7DmJ07dzrs78iRI5WcnGy9z8rKUo0aNdS1a1f5+/s7ufX2cnNzlZqaqmc2uis7361Yy2wbE3dZ67wSFOTllltukaenZ3l3x2WQF8fIi2PkxTFXy0vB1VpFoVgHAAClLjExUdu2bdPXX39d3l0pFi8vL3l5eRWa7unpWWIHetn5bsrOK16x7goHl2WlJHN8NSEvjpEXx8iLY66Sl+L2gQfMAQCAUpWUlKQFCxZoxYoVql69ujU9LCxMOTk5Onr0qF18ZmamwsLCrJjznw5f8L6oGH9/f/n4+KhKlSry8PBwGFPQBgAAroZiHQAAlApjjJKSkvTJJ59o+fLlioyMtJsfFRUlT09PLVu2zJq2a9cu7d+/XzExMZKkmJgYbd261e6p7ampqfL391fDhg2tmHPbKIgpaMNmsykqKsouJj8/X8uWLbNiAABwNVwGDwAASkViYqJmz56tTz/9VJUqVbLuMQ8ICJCPj48CAgKUkJCg5ORkBQcHy9/fXw8//LBiYmLUpk0bSVLXrl3VsGFDPfDAA5o4caIyMjL09NNPKzEx0bpM/aGHHtKrr76qxx9/XAMHDtTy5cv18ccfa+HChVZfkpOT1a9fP7Vs2VKtW7fW1KlTdfLkSevp8AAAuBqKdQAAUCpef/11SVLHjh3tps+cOVP9+/eXJE2ZMkXu7u7q1auXsrOzFRcXp9dee82K9fDw0IIFCzR06FDFxMSoYsWK6tevn8aNG2fFREZGauHChRo+fLimTZum6tWr66233rKGbZOk3r1769ChQxo1apQyMjLUvHlzLV68uNBD5wAAcBUU6wAAoFQYU/Q44t7e3po+fbqmT59+wZiIiIgihy7r2LGjNm/efNGYpKQkJSUlFdknAABcAfesAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAAAAAHAxJV6sjxkzRm5ubnav+vXrW/PPnDmjxMREVa5cWX5+furVq5cyMzPt2ti/f7/i4+Pl6+urqlWrasSIETp79qxdzMqVK3XjjTfKy8tLderUUUpKSklvCgAAAAAA5aJUzqw3atRIBw4csF5ff/21NW/48OH6/PPPNXfuXK1atUq///67evbsac3Py8tTfHy8cnJytHbtWs2aNUspKSkaNWqUFbN3717Fx8erU6dO2rJli4YNG6ZBgwZpyZIlpbE5AAAAAACUqQql0miFCgoLCys0/dixY3r77bc1e/Zsde7cWZI0c+ZMNWjQQOvWrVObNm20dOlS7dixQ19++aVCQ0PVvHlzjR8/Xk888YTGjBkjm82mGTNmKDIyUpMmTZIkNWjQQF9//bWmTJmiuLi40tgkAAAAAADKTKkU6z/++KPCw8Pl7e2tmJgYTZgwQTVr1lR6erpyc3MVGxtrxdavX181a9ZUWlqa2rRpo7S0NDVp0kShoaFWTFxcnIYOHart27erRYsWSktLs2ujIGbYsGEX7Vd2drays7Ot91lZWZKk3Nxc5ebmXnTZgvlFxRWXl4cpkXbKU1nn7GpHvpxHzpxDvpxX3JyRUwAAUNJKvFiPjo5WSkqK6tWrpwMHDmjs2LFq166dtm3bpoyMDNlsNgUGBtotExoaqoyMDElSRkaGXaFeML9g3sVisrKydPr0afn4+Djs24QJEzR27NhC05cuXSpfX99ibV9qamqx4ooysXWJNFOuFi1aVKy4ksrZtYJ8OY+cOYd8Oa+onJ06daqMegIAAK4VJV6sd+/e3fp/06ZNFR0drYiICH388ccXLKLLysiRI5WcnGy9z8rKUo0aNdS1a1f5+/tfdNnc3Fylpqbqlltukaen52X3pfGYK//++m1jLn7LQUnn7GpHvpxHzpxDvpxX3JwVXKkFAABQUkrlMvhzBQYG6oYbbtDu3bt1yy23KCcnR0ePHrU7u56ZmWnd4x4WFqYNGzbYtVHwtPhzY85/gnxmZqb8/f0v+gcBLy8veXl5FZru6elZ7ANXZ2IvJjvP7bLbKG9lnbNrBflyHjlzDvlyXlE5I58AAKCklfo46ydOnNCePXtUrVo1RUVFydPTU8uWLbPm79q1S/v371dMTIwkKSYmRlu3btXBgwetmNTUVPn7+6thw4ZWzLltFMQUtAEAAAAAwJWsxIv1xx57TKtWrdK+ffu0du1a3XnnnfLw8FDfvn0VEBCghIQEJScna8WKFUpPT9eAAQMUExOjNm3aSJK6du2qhg0b6oEHHtC3336rJUuW6Omnn1ZiYqJ1Vvyhhx7STz/9pMcff1w7d+7Ua6+9po8//ljDhw8v6c0BAAAAAKDMlfhl8L/++qv69u2rP//8UyEhIWrbtq3WrVunkJAQSdKUKVPk7u6uXr16KTs7W3FxcXrttdes5T08PLRgwQINHTpUMTExqlixovr166dx48ZZMZGRkVq4cKGGDx+uadOmqXr16nrrrbcYtg0AAAAAcFUo8WL9o48+uuh8b29vTZ8+XdOnT79gTERERJFPGu/YsaM2b958SX0EAAAAAMCVlfo96wAAAAAAwDkU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF1PiT4PHtaPWkwsvOt/Lw2hia6nxmCXKznPTvufjy6hnAAAAAHBl48w6AAAoFatXr9btt9+u8PBwubm5af78+XbzjTEaNWqUqlWrJh8fH8XGxurHH3+0izl8+LDuu+8++fv7KzAwUAkJCTpx4oRdzHfffad27drJ29tbNWrU0MSJEwv1Ze7cuapfv768vb3VpEmTIoeIBQCgvFGsAwCAUnHy5Ek1a9ZM06dPdzh/4sSJevnllzVjxgytX79eFStWVFxcnM6cOWPF3Hfffdq+fbtSU1O1YMECrV69WkOGDLHmZ2VlqWvXroqIiFB6erpefPFFjRkzRm+++aYVs3btWvXt21cJCQnavHmzevTooR49emjbtm2lt/EAAFwmLoMHAAClonv37urevbvDecYYTZ06VU8//bTuuOMOSdK7776r0NBQzZ8/X3369NH333+vxYsX65tvvlHLli0lSa+88opuvfVWvfTSSwoPD9cHH3ygnJwcvfPOO7LZbGrUqJG2bNmiyZMnW0X9tGnT1K1bN40YMUKSNH78eKWmpurVV1/VjBkzyiATAAA4j2IdAACUub179yojI0OxsbHWtICAAEVHRystLU19+vRRWlqaAgMDrUJdkmJjY+Xu7q7169frzjvvVFpamtq3by+bzWbFxMXF6YUXXtCRI0cUFBSktLQ0JScn260/Li6u0GX558rOzlZ2drb1PisrS5KUm5ur3Nzcy9r2guW93I3Ty1zNCrbxWthWZ5AXx8iLY+TFMVfLS3H7QbEOAADKXEZGhiQpNDTUbnpoaKg1LyMjQ1WrVrWbX6FCBQUHB9vFREZGFmqjYF5QUJAyMjIuuh5HJkyYoLFjxxaavnTpUvn6+hZnE4s0vmV+sWOvpXvsU1NTy7sLLom8OEZeHCMvjrlKXk6dOlWsOIp1AACA84wcOdLubHxWVpZq1Kihrl27yt/f/7Lazs3NVWpqqp7Z6K7sfLdiLbNtTNxlrfNKUJCXW265RZ6enuXdHZdBXhwjL46RF8dcLS8FV2sVhWIdAACUubCwMElSZmamqlWrZk3PzMxU8+bNrZiDBw/aLXf27FkdPnzYWj4sLEyZmZl2MQXvi4opmO+Il5eXvLy8Ck339PQssQO97Hw3ZecVr1h3hYPLslKSOb6akBfHyItj5MUxV8lLcfvA0+ABAECZi4yMVFhYmJYtW2ZNy8rK0vr16xUTEyNJiomJ0dGjR5Wenm7FLF++XPn5+YqOjrZiVq9ebXf/X2pqqurVq6egoCAr5tz1FMQUrAcAAFdEsQ4AAErFiRMntGXLFm3ZskXSXw+V27Jli/bv3y83NzcNGzZMzz77rD777DNt3bpVDz74oMLDw9WjRw9JUoMGDdStWzcNHjxYGzZs0Jo1a5SUlKQ+ffooPDxcknTvvffKZrMpISFB27dv15w5czRt2jS7S9gfffRRLV68WJMmTdLOnTs1ZswYbdy4UUlJSWWdEgAAio3L4AEAQKnYuHGjOnXqZL0vKKD79eunlJQUPf744zp58qSGDBmio0ePqm3btlq8eLG8vb2tZT744AMlJSWpS5cucnd3V69evfTyyy9b8wMCArR06VIlJiYqKipKVapU0ahRo+zGYr/ppps0e/ZsPf3003rqqadUt25dzZ8/X40bNy6DLAAAcGko1gEAQKno2LGjjLnw8GRubm4aN26cxo0bd8GY4OBgzZ49+6Lradq0qb766quLxtx99926++67L95hAABcCJfBAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAAAAAHAxFOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVUKO8O4NpR68mFTi+z7/n4UugJAAAAALg2zqwDAAAAAOBiKNYBAAAAAHAxFOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABfD0G0l5FKGJQMAAAAAwBGKdQAAABfn7EmBfc/Hl1JPAABlhcvgAQAAAABwMZxZh0vjTAIAAACAaxFn1gEAAAAAcDFXfLE+ffp01apVS97e3oqOjtaGDRvKu0sAAMBFcdwAALhSXNHF+pw5c5ScnKzRo0dr06ZNatasmeLi4nTw4MHy7hoAAHAxHDcAAK4kV/Q965MnT9bgwYM1YMAASdKMGTO0cOFCvfPOO3ryySfLuXcoD9zjDgC4kGvpuIHfhwBw5btii/WcnBylp6dr5MiR1jR3d3fFxsYqLS3N4TLZ2dnKzs623h87dkySdPjwYeXm5l50fbm5uTp16pT+/PNPeXp6Fppf4ezJS9mMq1qFfKNTp/JVIdddeflu5d0dh+o89rHTy6wf2aUUelL0PobCyJlzyJfzipuz48ePS5KMMWXVNTjJ2eOGyzlmKErBfuVKvx9d4fchP6McIy+OkRfHyItjrpaX4h43XLHF+h9//KG8vDyFhobaTQ8NDdXOnTsdLjNhwgSNHTu20PTIyMhS6SOke8u7A6WgyqTy7gEAV3X8+HEFBASUdzfggLPHDRwzFI3fhwBweYo6brhii/VLMXLkSCUnJ1vv8/PzdfjwYVWuXFlubhf/y3ZWVpZq1KihX375Rf7+/qXd1asCOXMO+XIeOXMO+XJecXNmjNHx48cVHh5ehr1DabqcY4ai8F10jLw4Rl4cIy+OkRfHXC0vxT1uuGKL9SpVqsjDw0OZmZl20zMzMxUWFuZwGS8vL3l5edlNCwwMdGq9/v7+LvEBX0nImXPIl/PImXPIl/OKkzPOqLs2Z48bSuKYoSh8Fx0jL46RF8fIi2PkxTFXyktxjhuu2KfB22w2RUVFadmyZda0/Px8LVu2TDExMeXYMwAA4Go4bgAAXGmu2DPrkpScnKx+/fqpZcuWat26taZOnaqTJ09aT3kFAAAowHEDAOBKckUX671799ahQ4c0atQoZWRkqHnz5lq8eHGhh8eUBC8vL40ePbrQJXG4MHLmHPLlPHLmHPLlPHJ2dSnL44aLYb9yjLw4Rl4cIy+OkRfHrtS8uBnGmQEAAAAAwKVcsfesAwAAAABwtaJYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIr1Ypo+fbpq1aolb29vRUdHa8OGDeXdpXKxevVq3X777QoPD5ebm5vmz59vN98Yo1GjRqlatWry8fFRbGysfvzxR7uYw4cP67777pO/v78CAwOVkJCgEydOlOFWlJ0JEyaoVatWqlSpkqpWraoePXpo165ddjFnzpxRYmKiKleuLD8/P/Xq1UuZmZl2Mfv371d8fLx8fX1VtWpVjRgxQmfPni3LTSkzr7/+upo2bSp/f3/5+/srJiZGX3zxhTWffF3c888/Lzc3Nw0bNsyaRs7sjRkzRm5ubnav+vXrW/PJF0rTtXY8wfftL2V1/PTdd9+pXbt28vb2Vo0aNTRx4sTS3rTLUlRe+vfvX2j/6datm13M1ZaXsjx2XLlypW688UZ5eXmpTp06SklJKe3Nu2TFyUvHjh0L7S8PPfSQXcwVlxeDIn300UfGZrOZd955x2zfvt0MHjzYBAYGmszMzPLuWplbtGiR+de//mX+97//GUnmk08+sZv//PPPm4CAADN//nzz7bffmr/97W8mMjLSnD592orp1q2badasmVm3bp356quvTJ06dUzfvn3LeEvKRlxcnJk5c6bZtm2b2bJli7n11ltNzZo1zYkTJ6yYhx56yNSoUcMsW7bMbNy40bRp08bcdNNN1vyzZ8+axo0bm9jYWLN582azaNEiU6VKFTNy5Mjy2KRS99lnn5mFCxeaH374wezatcs89dRTxtPT02zbts0YQ74uZsOGDaZWrVqmadOm5tFHH7WmkzN7o0ePNo0aNTIHDhywXocOHbLmky+UlmvxeILv21/K4vjp2LFjJjQ01Nx3331m27Zt5sMPPzQ+Pj7mjTfeKKvNdFpReenXr5/p1q2b3f5z+PBhu5irLS9ldez4008/GV9fX5OcnGx27NhhXnnlFePh4WEWL15cpttbXMXJS4cOHczgwYPt9pdjx45Z86/EvFCsF0Pr1q1NYmKi9T4vL8+Eh4ebCRMmlGOvyt/5P1Tz8/NNWFiYefHFF61pR48eNV5eXubDDz80xhizY8cOI8l88803VswXX3xh3NzczG+//VZmfS8vBw8eNJLMqlWrjDF/5cfT09PMnTvXivn++++NJJOWlmaM+esXmbu7u8nIyLBiXn/9dePv72+ys7PLdgPKSVBQkHnrrbfI10UcP37c1K1b16SmppoOHTpYxTo5K2z06NGmWbNmDueRL5Sma/F4gu9bYaV1/PTaa6+ZoKAgu7w88cQTpl69eqW8RSXjQsX6HXfcccFlroW8lNax4+OPP24aNWpkt67evXubuLi40t6kEnF+Xowxdsc/jlyJeeEy+CLk5OQoPT1dsbGx1jR3d3fFxsYqLS2tHHvmevbu3auMjAy7XAUEBCg6OtrKVVpamgIDA9WyZUsrJjY2Vu7u7lq/fn2Z97msHTt2TJIUHBwsSUpPT1dubq5dzurXr6+aNWva5axJkyYKDQ21YuLi4pSVlaXt27eXYe/LXl5enj766COdPHlSMTEx5OsiEhMTFR8fb5cbiX3sQn788UeFh4fr+uuv13333af9+/dLIl8oPdfy8QTft4srqeOntLQ0tW/fXjabzYqJi4vTrl27dOTIkTLampK3cuVKVa1aVfXq1dPQoUP1559/WvOuhbyU1rFjWlpaoWOGuLi4K+bn0fl5KfDBBx+oSpUqaty4sUaOHKlTp05Z867EvFQol7VeQf744w/l5eXZfaiSFBoaqp07d5ZTr1xTRkaGJDnMVcG8jIwMVa1a1W5+hQoVFBwcbMVcrfLz8zVs2DDdfPPNaty4saS/8mGz2RQYGGgXe37OHOW0YN7VaOvWrYqJidGZM2fk5+enTz75RA0bNtSWLVvIlwMfffSRNm3apG+++abQPPaxwqKjo5WSkqJ69erpwIEDGjt2rNq1a6dt27aRL5Saa/V4gu9b0Urq+CkjI0ORkZGF2iiYFxQUVCr9L03dunVTz549FRkZqT179uipp55S9+7dlZaWJg8Pj6s+L6V57HihmKysLJ0+fVo+Pj6lsUklwlFeJOnee+9VRESEwsPD9d133+mJJ57Qrl279L///U/SlZkXinWgjCQmJmrbtm36+uuvy7srLq9evXrasmWLjh07pnnz5qlfv35atWpVeXfLJf3yyy969NFHlZqaKm9v7/LuzhWhe/fu1v+bNm2q6OhoRURE6OOPP3bpgxPgSsT3DZejT58+1v+bNGmipk2bqnbt2lq5cqW6dOlSjj0rGxw7OnahvAwZMsT6f5MmTVStWjV16dJFe/bsUe3atcu6myWCy+CLUKVKFXl4eBR6wmJmZqbCwsLKqVeuqSAfF8tVWFiYDh48aDf/7NmzOnz48FWdz6SkJC1YsEArVqxQ9erVrelhYWHKycnR0aNH7eLPz5mjnBbMuxrZbDbVqVNHUVFRmjBhgpo1a6Zp06aRLwfS09N18OBB3XjjjapQoYIqVKigVatW6eWXX1aFChUUGhpKzooQGBioG264Qbt372YfQ6nheOIvfN8KK6njp2shV9dff72qVKmi3bt3S7q681Lax44XivH393fpP6RdKC+OREdHS5Ld/nKl5YVivQg2m01RUVFatmyZNS0/P1/Lli1TTExMOfbM9URGRiosLMwuV1lZWVq/fr2Vq5iYGB09elTp6elWzPLly5Wfn299oa4mxhglJSXpk08+0fLlywtdhhUVFSVPT0+7nO3atUv79++3y9nWrVvtfhmlpqbK399fDRs2LJsNKWf5+fnKzs4mXw506dJFW7du1ZYtW6xXy5Ytdd9991n/J2cXd+LECe3Zs0fVqlVjH0Op4XjiL3zfCiup46eYmBitXr1aubm5Vkxqaqrq1avn0pd6O+PXX3/Vn3/+qWrVqkm6OvNSVseOMTExdm0UxLjqz6Oi8uLIli1bJMluf7ni8lIuj7W7wnz00UfGy8vLpKSkmB07dpghQ4aYwMBAuycJXiuOHz9uNm/ebDZv3mwkmcmTJ5vNmzebn3/+2Rjz19AjgYGB5tNPPzXfffedueOOOxwOPdKiRQuzfv168/XXX5u6detetUO3DR061AQEBJiVK1faDSNx6tQpK+ahhx4yNWvWNMuXLzcbN240MTExJiYmxppfMMxE165dzZYtW8zixYtNSEjIFTdsTXE9+eSTZtWqVWbv3r3mu+++M08++aRxc3MzS5cuNcaQr+I4/2mo5MzeP//5T7Ny5Uqzd+9es2bNGhMbG2uqVKliDh48aIwhXyg91+LxBN+3v5TF8dPRo0dNaGioeeCBB8y2bdvMRx99ZHx9fV12iDJjLp6X48ePm8cee8ykpaWZvXv3mi+//NLceOONpm7duubMmTNWG1dbXsrq2LFgiLIRI0aY77//3kyfPt2lh24rKi+7d+8248aNMxs3bjR79+41n376qbn++utN+/btrTauxLxQrBfTK6+8YmrWrGlsNptp3bq1WbduXXl3qVysWLHCSCr06tevnzHmr+FHnnnmGRMaGmq8vLxMly5dzK5du+za+PPPP03fvn2Nn5+f8ff3NwMGDDDHjx8vh60pfY5yJcnMnDnTijl9+rT5xz/+YYKCgoyvr6+58847zYEDB+za2bdvn+nevbvx8fExVapUMf/85z9Nbm5uGW9N2Rg4cKCJiIgwNpvNhISEmC5duliFujHkqzjOL9bJmb3evXubatWqGZvNZq677jrTu3dvs3v3bms++UJputaOJ/i+/aWsjp++/fZb07ZtW+Pl5WWuu+468/zzz5fVJl6Si+Xl1KlTpmvXriYkJMR4enqaiIgIM3jw4EJ/3Lra8lKWx44rVqwwzZs3NzabzVx//fV263A1ReVl//79pn379iY4ONh4eXmZOnXqmBEjRtiNs27MlZcXN2OMKd1z9wAAAAAAwBncsw4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLoVgHAAAAAMDFUKwDAAAAAOBiKNYBAAAAAHAxFOsAAAAAALgYinUAAAAAAFwMxToAAAAAAC6GYh0AAAAAABdDsQ4AAAAAgIuhWAcAAAAAwMVQrAMAAAAA4GIo1gEAAAAAcDEU6wAAAAAAuBiKdQAAAAAAXAzFOgAAAAAALoZiHQAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrQDnp2LGjGjduXN7dAAAAAOCCKNYBOO25557T/Pnzy7sbZWrRokUaM2ZMmazr1KlTGjNmjFauXFkm6wMAAIDroVgH4LRrtVgfO3Zsmazr1KlTGjt2LMU6AADANYxiHbiKnT17Vjk5OeXdjWI5c+aM8vPzy7sbAAAAgEugWIfLGzNmjNzc3LR79271799fgYGBCggI0IABA3Tq1ClJ0r59++Tm5qaUlJRCy7u5udldvlzQ3g8//KD7779fAQEBCgkJ0TPPPCNjjH755Rfdcccd8vf3V1hYmCZNmnRJ/f7iiy/UoUMHVapUSf7+/mrVqpVmz55dKG7Hjh3q1KmTfH19dd1112nixIl283NycjRq1ChFRUUpICBAFStWVLt27bRixQq7uIIcvPTSS5o6dapq164tLy8v7dixo9htSFJ+fr6mTZumJk2ayNvbWyEhIerWrZs2btxo5fPkyZOaNWuW3Nzc5Obmpv79+1vL//bbbxo4cKBCQ0Pl5eWlRo0a6Z133rFbx8qVK+Xm5qaPPvpITz/9tK677jr5+voqKytLubm5Gjt2rOrWrStvb29VrlxZbdu2VWpqqlP5P3jwoBISEhQaGipvb281a9ZMs2bNctiP889gn78/9e/fX9OnT7e2v+B1ft6nTJmiiIgI+fj4qEOHDtq2bZtdux07dlTHjh0L9bV///6qVauW1V5ISIgkaezYsda6yuoSfAAAALiGCuXdAaC47rnnHkVGRmrChAnatGmT3nrrLVWtWlUvvPDCJbXXu3dvNWjQQM8//7wWLlyoZ599VsHBwXrjjTfUuXNnvfDCC/rggw/02GOPqVWrVmrfvn2x205JSdHAgQPVqFEjjRw5UoGBgdq8ebMWL16se++914o7cuSIunXrpp49e+qee+7RvHnz9MQTT6hJkybq3r27JCkrK0tvvfWW+vbtq8GDB+v48eN6++23FRcXpw0bNqh58+Z26545c6bOnDmjIUOGyMvLS8HBwU61kZCQoJSUFHXv3l2DBg3S2bNn9dVXX2ndunVq2bKl3nvvPQ0aNEitW7fWkCFDJEm1a9eWJGVmZqpNmzZyc3NTUlKSQkJC9MUXXyghIUFZWVkaNmyYXV/Hjx8vm82mxx57TNnZ2bLZbBozZowmTJhgrSMrK0sbN27Upk2bdMsttxQr/6dPn1bHjh21e/duJSUlKTIyUnPnzlX//v119OhRPfroo8X+LCXp73//u37//Xelpqbqvffecxjz7rvv6vjx40pMTNSZM2c0bdo0de7cWVu3blVoaGix1xUSEqLXX39dQ4cO1Z133qmePXtKkpo2bepUnwEAAHCFM4CLGz16tJFkBg4caDf9zjvvNJUrVzbGGLN3714jycycObPQ8pLM6NGjC7U3ZMgQa9rZs2dN9erVjZubm3n++eet6UeOHDE+Pj6mX79+xe7v0aNHTaVKlUx0dLQ5ffq03bz8/Hzr/x06dDCSzLvvvmtNy87ONmFhYaZXr152fcvOzrZr58iRIyY0NNQuJwU58Pf3NwcPHrSLL24by5cvN5LMI488Umi7zu17xYoVHeYkISHBVKtWzfzxxx920/v06WMCAgLMqVOnjDHGrFixwkgy119/vTWtQLNmzUx8fHyhtp0xdepUI8m8//771rScnBwTExNj/Pz8TFZWll0/VqxYYbe8o/0pMTHROPqRWRDr4+Njfv31V2v6+vXrjSQzfPhwa1qHDh1Mhw4dCrXRr18/ExERYb0/dOhQof0WAAAA1xYug8cV46GHHrJ7365dO/3555/Kysq6pPYGDRpk/d/Dw0MtW7aUMUYJCQnW9MDAQNWrV08//fRTsdtNTU3V8ePH9eSTT8rb29tuXsGl0wX8/Px0//33W+9tNptat25ttz4PDw/ZbDZJf12ifvjwYZ09e1YtW7bUpk2bCq2/V69e1mXUzrbx3//+V25ubho9enShds/v+/mMMfrvf/+r22+/XcYY/fHHH9YrLi5Ox44dK9Tffv36ycfHx25aYGCgtm/frh9//PGi67uYRYsWKSwsTH379rWmeXp66pFHHtGJEye0atWqS277Qnr06KHrrrvOet+6dWtFR0dr0aJFJb4uAAAAXP0o1nHFqFmzpt37oKAgSX9dSl4S7QUEBMjb21tVqlQpNN2ZdezZs0eSijWGevXq1QsVwUFBQYXWN2vWLDVt2tS6hzskJEQLFy7UsWPHCrUZGRnpcF3FaWPPnj0KDw9XcHBwkX0/36FDh3T06FG9+eabCgkJsXsNGDBA0l/3kRfV13Hjxuno0aO64YYb1KRJE40YMULfffedU335+eefVbduXbm72/+Ia9CggTW/pNWtW7fQtBtuuEH79u0r8XUBAADg6sc967hieHh4OJxujLngWd+8vDyn2rvYOkpDcdb3/vvvq3///urRo4dGjBihqlWrysPDQxMmTLD+MHCu889UX0obl6LgSe7333+/+vXr5zDm/PuuHfW1ffv22rNnjz799FMtXbpUb731lqZMmaIZM2bYXQ1REi5lv7nc9Tnal0prfQAAALhyUazjqlBwlv3o0aN200vjDGpRCh62tm3bNtWpU+ey25s3b56uv/56/e9//7MrLh1dqn65bdSuXVtLlizR4cOHL3p23VGRGxISokqVKikvL0+xsbHF7psjwcHBGjBggAYMGKATJ06offv2GjNmTLGL9YiICH333XfKz8+3O7u+c+dOa77k3H5T1G0Aji7b/+GHH6ynvBesz9EtFeevr6h1AQAA4OrHZfC4Kvj7+6tKlSpavXq13fTXXnutzPvStWtXVapUSRMmTNCZM2fs5l3KGfqCs+/nLrt+/XqlpaWVeBu9evWSMUZjx44t1Ma5y1asWLFQgevh4aFevXrpv//9b6Ehy6S/LpMvjj///NPuvZ+fn+rUqaPs7OxiLS9Jt956qzIyMjRnzhxr2tmzZ/XKK6/Iz89PHTp0kPRX0e7h4VGs/aZixYqSChf2BebPn6/ffvvNer9hwwatX7/eeqq/9NcfQ3bu3GmXi2+//VZr1qyxa8vX1/ei6wIAAMDVjzPruGoMGjRIzz//vAYNGqSWLVtq9erV+uGHH8q8H/7+/poyZYoGDRqkVq1a6d5771VQUJC+/fZbnTp1qtBY30W57bbb9L///U933nmn4uPjtXfvXs2YMUMNGzbUiRMnSrSNTp066YEHHtDLL7+sH3/8Ud26dVN+fr6++uorderUSUlJSZKkqKgoffnll5o8ebLCw8MVGRmp6OhoPf/881qxYoWio6M1ePBgNWzYUIcPH9amTZv05Zdf6vDhw0X2tWHDhurYsaOioqIUHBysjRs3at68eda6i2PIkCF644031L9/f6Wnp6tWrVqaN2+e1qxZo6lTp6pSpUqS/noewd13361XXnlFbm5uql27thYsWFDo3vqCbZakRx55RHFxcfLw8FCfPn2s+XXq1FHbtm01dOhQZWdna+rUqapcubIef/xxK2bgwIGaPHmy4uLilJCQoIMHD2rGjBlq1KiR3YMSfXx81LBhQ82ZM0c33HCDgoOD1bhx42I9BwEAAABXifJ5CD1QfAVDrR06dMhu+syZM40ks3fvXmOMMadOnTIJCQkmICDAVKpUydxzzz3m4MGDFxy67fz2+vXrZypWrFho/R06dDCNGjVyut+fffaZuemmm4yPj4/x9/c3rVu3Nh9++GGR7Z4/jFd+fr557rnnTEREhPHy8jItWrQwCxYsKBRXMITYiy++WKjN4rZhzF/DvL344oumfv36xmazmZCQENO9e3eTnp5uxezcudO0b9/e+Pj4GEl2w7hlZmaaxMREU6NGDePp6WnCwsJMly5dzJtvvmnFFAyZNnfu3EJ9ffbZZ03r1q1NYGCg8fHxMfXr1zf//ve/TU5OzsXSXUhmZqYZMGCAqVKlirHZbKZJkyYOh/Y7dOiQ6dWrl/H19TVBQUHm73//u9m2bVuhodvOnj1rHn74YRMSEmLc3NysYdzOzfukSZNMjRo1jJeXl2nXrp359ttvC63v/fffN9dff72x2WymefPmZsmSJQ4/h7Vr15qoqChjs9kYxg0AAOAa5GZMKT05CwCuAfv27VNkZKRefPFFPfbYY+XdHQAAAFwluGcdAAAAAAAXwz3rgBMOHTp00WG2bDbbJY1RjuLJyckp8r73gIAAh0PCAQAAAFcSinXACa1atbrocHAdOnTQypUry65D15i1a9eqU6dOF42ZOXOm+vfvXzYdAgAAAEoJ96wDTlizZo1Onz59wflBQUHWU8NR8o4cOaL09PSLxjRq1EjVqlUrox4BAAAApYNiHQAAAAAAF3NNXwafn5+v33//XZUqVZKbm1t5dwcAcIUyxuj48eMKDw+XuzvPbgUAAJfvmi7Wf//9d9WoUaO8uwEAuEr88ssvql69enl3AwAAXAWu6WK9UqVKkv46uPL397/kdnJzc7V06VJ17dpVnp6eJdW9csd2XVnYrivP1bpt1+J2ZWVlqUaNGtbvFQAAgMt1TRfrBZe++/v7X3ax7uvrK39//6vuwJTtunKwXVeeq3XbruXt4pYqAABQUrixDgAAAAAAF0OxDgAAAACAi6FYBwAAAADAxVCsAwAAAADgYijWAQAAAABwMRTrAAAAAAC4GIp1AAAAAABcDMU6AAAAAAAuhmIdAAAAAAAXQ7EOAAAAAICLqVDeHbiaNB6zRNl5bsWK3fd8fCn3BgAAAABwpeLMOgAAAAAALsapYn3MmDFyc3Oze9WvX9+af+bMGSUmJqpy5cry8/NTr169lJmZadfG/v37FR8fL19fX1WtWlUjRozQ2bNn7WJWrlypG2+8UV5eXqpTp45SUlIK9WX69OmqVauWvL29FR0drQ0bNjizKQAAAAAAuCynz6w3atRIBw4csF5ff/21NW/48OH6/PPPNXfuXK1atUq///67evbsac3Py8tTfHy8cnJytHbtWs2aNUspKSkaNWqUFbN3717Fx8erU6dO2rJli4YNG6ZBgwZpyZIlVsycOXOUnJys0aNHa9OmTWrWrJni4uJ08ODBS80DAAAAAAAuw+livUKFCgoLC7NeVapUkSQdO3ZMb7/9tiZPnqzOnTsrKipKM2fO1Nq1a7Vu3TpJ0tKlS7Vjxw69//77at68ubp3767x48dr+vTpysnJkSTNmDFDkZGRmjRpkho0aKCkpCTdddddmjJlitWHyZMna/DgwRowYIAaNmyoGTNmyNfXV++8805J5AQAAAAAgHLl9APmfvzxR4WHh8vb21sxMTGaMGGCatasqfT0dOXm5io2NtaKrV+/vmrWrKm0tDS1adNGaWlpatKkiUJDQ62YuLg4DR06VNu3b1eLFi2UlpZm10ZBzLBhwyRJOTk5Sk9P18iRI6357u7uio2NVVpa2kX7np2drezsbOt9VlaWJCk3N1e5ubnOpsJSsKyXu3F6GVdW0Mcroa/OYLuuLFfrdklX77Zdi9t1tW0rAAAof04V69HR0UpJSVG9evV04MABjR07Vu3atdO2bduUkZEhm82mwMBAu2VCQ0OVkZEh/b/27j06qvrc//gnCckkASfhYhIotygKRG4SSphWLUpIwCwrSlukLI2IWDiJR0gLmB7KtefAgQqiBPFUIJ6lVqCr4pFQIIabSgCJRLkISykae2SCFZJwTYbk+/ujv9mHMRBJSMie4f1ai7Uy3/3sPc+zt1krH2dmjyS32+0T1L3bvdvqqqmoqND58+d16tQpVVdXX7bm8OHDdfY/b948zZ49u9b65s2bFRkZ+f0n4HvMHVBz1bUbNmy45ue7XvLz85u7hSbBXP4lUOeSAne2G2muc+fONUMnAAAgkNUrrA8fPtz6uU+fPkpKSlKXLl20Zs0aRURENHpzjS07O1tZWVnW44qKCnXq1EkpKSlyOp0NPq7H41F+fr5+tzdYlTVX99VtB2alNvj5rhfvXEOHDlVoaGhzt9NomMu/BOpcUuDOdiPO5X2nFgAAQGO5pu9Zj46O1u23367PP/9cQ4cOVVVVlcrKynxeXS8tLVVcXJwkKS4urtZd2713i7+05rt3kC8tLZXT6VRERIRCQkIUEhJy2RrvMa7E4XDI4XDUWg8NDW2UPygra4Ku+nvW/ekP2MY6P3bDXP4lUOeSAne2G2muQJwTAAA0r2v6nvUzZ87o6NGjat++vRITExUaGqqCggJr+5EjR1RSUiKXyyVJcrlc2r9/v89d2/Pz8+V0OpWQkGDVXHoMb433GGFhYUpMTPSpqampUUFBgVUDAAAAAIA/q1dY/81vfqPt27friy++0M6dO/XQQw8pJCREo0ePVlRUlMaNG6esrCxt3bpVRUVFGjt2rFwulwYNGiRJSklJUUJCgh599FF9/PHH2rRpk6ZPn66MjAzrFe8JEybob3/7m6ZOnarDhw9r2bJlWrNmjSZPnmz1kZWVpT/+8Y969dVX9emnn2rixIk6e/asxo4d24inBgAAAACA5lGvt8H//e9/1+jRo/Xtt9/q5ptv1l133aVdu3bp5ptvliQtXrxYwcHBGjlypCorK5Wamqply5ZZ+4eEhGj9+vWaOHGiXC6XWrZsqfT0dM2ZM8eqiY+PV15eniZPnqwlS5aoY8eOeuWVV5Sa+n+f8R41apS++eYbzZgxQ263W/369dPGjRtr3XQOAAAAAAB/VK+w/uabb9a5PTw8XDk5OcrJybliTZcuXb73TuiDBw/Wvn376qzJzMxUZmZmnTUAAAAAAPija/rMOgAAAAAAaHyEdQAAAAAAbIawDgAAAACAzRDWAQAAAACwGcI6AAAAAAA2Q1gHAAAAAMBmCOsAAAAAANgMYR0AAAAAAJshrAMAAAAAYDOEdQAAAAAAbIawDgAAAACAzRDWAQAAAACwGcI6AAAAAAA2Q1gHAAAAAMBmCOsAAAAAANgMYR0AAAAAAJshrAMAAAAAYDOEdQAAAAAAbIawDgAAAACAzRDWAQAAAACwGcI6AAAAAAA2Q1gHAAAAAMBmCOsAAAAAANgMYR0AAAAAAJshrAMAAAAAYDOEdQAAAAAAbIawDgAAAACAzRDWAQAAAACwGcI6AAAAAAA2Q1gHAAAAAMBmCOsAAAAAANgMYR0AAAAAAJshrAMAAAAAYDOEdQAAAAAAbIawDgAAAACAzRDWAQAAAACwGcI6AAAAAAA2Q1gHAAAAAMBmCOsAAAAAANjMNYX1+fPnKygoSJMmTbLWLly4oIyMDLVt21atWrXSyJEjVVpa6rNfSUmJ0tLSFBkZqZiYGE2ZMkUXL170qdm2bZv69+8vh8Ohbt26KTc3t9bz5+TkqGvXrgoPD1dSUpL27NlzLeMAAAAAAGALDQ7rH374oV5++WX16dPHZ33y5Ml65513tHbtWm3fvl1ff/21Hn74YWt7dXW10tLSVFVVpZ07d+rVV19Vbm6uZsyYYdUcO3ZMaWlpuvfee1VcXKxJkybpySef1KZNm6ya1atXKysrSzNnztRHH32kvn37KjU1VSdOnGjoSAAAAAAA2EKDwvqZM2c0ZswY/fGPf1Tr1q2t9fLycq1YsUKLFi3Sfffdp8TERK1atUo7d+7Url27JEmbN2/WoUOH9Nprr6lfv34aPny45s6dq5ycHFVVVUmSli9frvj4eD333HPq2bOnMjMz9bOf/UyLFy+2nmvRokUaP368xo4dq4SEBC1fvlyRkZFauXLltZwPAAAAAACaXYuG7JSRkaG0tDQlJyfr97//vbVeVFQkj8ej5ORka61Hjx7q3LmzCgsLNWjQIBUWFqp3796KjY21alJTUzVx4kQdPHhQd955pwoLC32O4a3xvt2+qqpKRUVFys7OtrYHBwcrOTlZhYWFV+y7srJSlZWV1uOKigpJksfjkcfjacipsPaXJEewqfc+dubt0R96rQ/m8i+BOpcUuLPdiHMF2qwAAKD51Tusv/nmm/roo4/04Ycf1trmdrsVFham6Ohon/XY2Fi53W6r5tKg7t3u3VZXTUVFhc6fP69Tp06purr6sjWHDx++Yu/z5s3T7Nmza61v3rxZkZGRV9zvas0dUHPVtRs2bLjm57te8vPzm7uFJsFc/iVQ55ICd7Ybaa5z5841QycAACCQ1Susf/XVV3rmmWeUn5+v8PDwpuqpyWRnZysrK8t6XFFRoU6dOiklJUVOp7PBx/V4PMrPz9fv9garsiboqvY5MCu1wc93vXjnGjp0qEJDQ5u7nUbDXP4lUOeSAne2G3Eu7zu1AAAAGku9wnpRUZFOnDih/v37W2vV1dXasWOHli5dqk2bNqmqqkplZWU+r66XlpYqLi5OkhQXF1frru3eu8VfWvPdO8iXlpbK6XQqIiJCISEhCgkJuWyN9xiX43A45HA4aq2HhoY2yh+UlTVBqqy+urDuT3/ANtb5sRvm8i+BOpcUuLPdSHMF4pwAAKB51esGc0OGDNH+/ftVXFxs/RswYIDGjBlj/RwaGqqCggJrnyNHjqikpEQul0uS5HK5tH//fp+7tufn58vpdCohIcGqufQY3hrvMcLCwpSYmOhTU1NTo4KCAqsGAAAAAAB/Va9X1m+66Sb16tXLZ61ly5Zq27attT5u3DhlZWWpTZs2cjqdevrpp+VyuTRo0CBJUkpKihISEvToo49qwYIFcrvdmj59ujIyMqxXvSdMmKClS5dq6tSpeuKJJ7RlyxatWbNGeXl51vNmZWUpPT1dAwYM0MCBA/X888/r7NmzGjt27DWdEAAAAAAAmluD7gZfl8WLFys4OFgjR45UZWWlUlNTtWzZMmt7SEiI1q9fr4kTJ8rlcqlly5ZKT0/XnDlzrJr4+Hjl5eVp8uTJWrJkiTp27KhXXnlFqan/9znvUaNG6ZtvvtGMGTPkdrvVr18/bdy4sdZN5wAAAAAA8DfXHNa3bdvm8zg8PFw5OTnKycm54j5dunT53ruhDx48WPv27auzJjMzU5mZmVfdKwAAAAAA/qBen1kHAAAAAABNj7AOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAm6lXWH/ppZfUp08fOZ1OOZ1OuVwu/fWvf7W2X7hwQRkZGWrbtq1atWqlkSNHqrS01OcYJSUlSktLU2RkpGJiYjRlyhRdvHjRp2bbtm3q37+/HA6HunXrptzc3Fq95OTkqGvXrgoPD1dSUpL27NlTn1EAAAAAALCteoX1jh07av78+SoqKtLevXt133336cEHH9TBgwclSZMnT9Y777yjtWvXavv27fr666/18MMPW/tXV1crLS1NVVVV2rlzp1599VXl5uZqxowZVs2xY8eUlpame++9V8XFxZo0aZKefPJJbdq0yapZvXq1srKyNHPmTH300Ufq27evUlNTdeLEiWs9HwAAAAAANLt6hfUHHnhA999/v2677Tbdfvvt+vd//3e1atVKu3btUnl5uVasWKFFixbpvvvuU2JiolatWqWdO3dq165dkqTNmzfr0KFDeu2119SvXz8NHz5cc+fOVU5OjqqqqiRJy5cvV3x8vJ577jn17NlTmZmZ+tnPfqbFixdbfSxatEjjx4/X2LFjlZCQoOXLlysyMlIrV65sxFMDAAAAAEDzaNHQHaurq7V27VqdPXtWLpdLRUVF8ng8Sk5Otmp69Oihzp07q7CwUIMGDVJhYaF69+6t2NhYqyY1NVUTJ07UwYMHdeedd6qwsNDnGN6aSZMmSZKqqqpUVFSk7Oxsa3twcLCSk5NVWFhYZ8+VlZWqrKy0HldUVEiSPB6PPB5PQ0+Fta8j2NR7Hzvz9ugPvdYHc/mXQJ1LCtzZbsS5Am1WAADQ/Ood1vfv3y+Xy6ULFy6oVatWeuutt5SQkKDi4mKFhYUpOjrapz42NlZut1uS5Ha7fYK6d7t3W101FRUVOn/+vE6dOqXq6urL1hw+fLjO3ufNm6fZs2fXWt+8ebMiIyO/f/jvMXdAzVXXbtiw4Zqf73rJz89v7haaBHP5l0CdSwrc2W6kuc6dO9cMnQAAgEBW77DevXt3FRcXq7y8XH/+85+Vnp6u7du3N0VvjS47O1tZWVnW44qKCnXq1EkpKSlyOp0NPq7H41F+fr5+tzdYlTVBV7XPgVmpDX6+68U719ChQxUaGtrc7TQa5vIvgTqXFLiz3Yhzed+pBQAA0FjqHdbDwsLUrVs3SVJiYqI+/PBDLVmyRKNGjVJVVZXKysp8Xl0vLS1VXFycJCkuLq7WXdu9d4u/tOa7d5AvLS2V0+lURESEQkJCFBISctka7zGuxOFwyOFw1FoPDQ1tlD8oK2uCVFl9dWHdn/6AbazzYzfM5V8CdS4pcGe7keYKxDkBAEDzuubvWa+pqVFlZaUSExMVGhqqgoICa9uRI0dUUlIil8slSXK5XNq/f7/PXdvz8/PldDqVkJBg1Vx6DG+N9xhhYWFKTEz0qampqVFBQYFVAwAAAACAP6vXK+vZ2dkaPny4OnfurNOnT+uNN97Qtm3btGnTJkVFRWncuHHKyspSmzZt5HQ69fTTT8vlcmnQoEGSpJSUFCUkJOjRRx/VggUL5Ha7NX36dGVkZFiveE+YMEFLly7V1KlT9cQTT2jLli1as2aN8vLyrD6ysrKUnp6uAQMGaODAgXr++ed19uxZjR07thFPDQAAAAAAzaNeYf3EiRN67LHHdPz4cUVFRalPnz7atGmThg4dKklavHixgoODNXLkSFVWVio1NVXLli2z9g8JCdH69es1ceJEuVwutWzZUunp6ZozZ45VEx8fr7y8PE2ePFlLlixRx44d9corryg19f8+4z1q1Ch98803mjFjhtxut/r166eNGzfWuukcAAAAAAD+qF5hfcWKFXVuDw8PV05OjnJycq5Y06VLl++9E/rgwYO1b9++OmsyMzOVmZlZZw0AAAAAAP7omj+zDgAAAAAAGhdhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZTr7A+b948/fCHP9RNN92kmJgYjRgxQkeOHPGpuXDhgjIyMtS2bVu1atVKI0eOVGlpqU9NSUmJ0tLSFBkZqZiYGE2ZMkUXL170qdm2bZv69+8vh8Ohbt26KTc3t1Y/OTk56tq1q8LDw5WUlKQ9e/bUZxwAAAAAAGypXmF9+/btysjI0K5du5Sfny+Px6OUlBSdPXvWqpk8ebLeeecdrV27Vtu3b9fXX3+thx9+2NpeXV2ttLQ0VVVVaefOnXr11VeVm5urGTNmWDXHjh1TWlqa7r33XhUXF2vSpEl68skntWnTJqtm9erVysrK0syZM/XRRx+pb9++Sk1N1YkTJ67lfAAAAAAA0Oxa1Kd448aNPo9zc3MVExOjoqIi3XPPPSovL9eKFSv0xhtv6L777pMkrVq1Sj179tSuXbs0aNAgbd68WYcOHdK7776r2NhY9evXT3PnztW0adM0a9YshYWFafny5YqPj9dzzz0nSerZs6fef/99LV68WKmpqZKkRYsWafz48Ro7dqwkafny5crLy9PKlSv17LPPXvOJAQAAAACgudQrrH9XeXm5JKlNmzaSpKKiInk8HiUnJ1s1PXr0UOfOnVVYWKhBgwapsLBQvXv3VmxsrFWTmpqqiRMn6uDBg7rzzjtVWFjocwxvzaRJkyRJVVVVKioqUnZ2trU9ODhYycnJKiwsvGK/lZWVqqystB5XVFRIkjwejzweTwPPgqx9HcGm3vvYmbdHf+i1PpjLvwTqXFLgznYjzhVoswIAgObX4LBeU1OjSZMm6cc//rF69eolSXK73QoLC1N0dLRPbWxsrNxut1VzaVD3bvduq6umoqJC58+f16lTp1RdXX3ZmsOHD1+x53nz5mn27Nm11jdv3qzIyMirmLpucwfUXHXthg0brvn5rpf8/PzmbqFJMJd/CdS5pMCd7Uaa69y5c83QCQAACGQNDusZGRk6cOCA3n///cbsp0llZ2crKyvLelxRUaFOnTopJSVFTqezwcf1eDzKz8/X7/YGq7Im6Kr2OTArtcHPd7145xo6dKhCQ0Obu51Gw1z+JVDnkgJ3thtxLu87tQAAABpLg8J6Zmam1q9frx07dqhjx47WelxcnKqqqlRWVubz6nppaani4uKsmu/etd17t/hLa757B/nS0lI5nU5FREQoJCREISEhl63xHuNyHA6HHA5HrfXQ0NBG+YOysiZIldVXF9b96Q/Yxjo/dsNc/iVQ55ICd7Ybaa5AnBMAADSvet0N3hijzMxMvfXWW9qyZYvi4+N9ticmJio0NFQFBQXW2pEjR1RSUiKXyyVJcrlc2r9/v89d2/Pz8+V0OpWQkGDVXHoMb433GGFhYUpMTPSpqampUUFBgVUDAAAAAIC/qtcr6xkZGXrjjTf09ttv66abbrI+Yx4VFaWIiAhFRUVp3LhxysrKUps2beR0OvX000/L5XJp0KBBkqSUlBQlJCTo0Ucf1YIFC+R2uzV9+nRlZGRYr3pPmDBBS5cu1dSpU/XEE09oy5YtWrNmjfLy8qxesrKylJ6ergEDBmjgwIF6/vnndfbsWevu8AAAAAAA+Kt6hfWXXnpJkjR48GCf9VWrVunxxx+XJC1evFjBwcEaOXKkKisrlZqaqmXLllm1ISEhWr9+vSZOnCiXy6WWLVsqPT1dc+bMsWri4+OVl5enyZMna8mSJerYsaNeeeUV62vbJGnUqFH65ptvNGPGDLndbvXr108bN26sddM5AAAAAAD8Tb3CujHf/9Vk4eHhysnJUU5OzhVrunTp8r13Qx88eLD27dtXZ01mZqYyMzO/tycAAAAAAPxJvT6zDgAAAAAAmh5hHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgMy2au4EbVddn8+pV/8X8tCbqBAAAAABgN7yyDgAAAACAzRDWAQAAAACwGcI6AAAAAAA2U++wvmPHDj3wwAPq0KGDgoKCtG7dOp/txhjNmDFD7du3V0REhJKTk/XZZ5/51Jw8eVJjxoyR0+lUdHS0xo0bpzNnzvjUfPLJJ7r77rsVHh6uTp06acGCBbV6Wbt2rXr06KHw8HD17t1bGzZsqO84AAAAAADYTr3D+tmzZ9W3b1/l5ORcdvuCBQv0wgsvaPny5dq9e7datmyp1NRUXbhwwaoZM2aMDh48qPz8fK1fv147duzQU089ZW2vqKhQSkqKunTpoqKiIi1cuFCzZs3Sf/3Xf1k1O3fu1OjRozVu3Djt27dPI0aM0IgRI3TgwIH6jgQAAAAAgK3U+27ww4cP1/Dhwy+7zRij559/XtOnT9eDDz4oSfrv//5vxcbGat26dXrkkUf06aefauPGjfrwww81YMAASdKLL76o+++/X3/4wx/UoUMHvf7666qqqtLKlSsVFhamO+64Q8XFxVq0aJEV6pcsWaJhw4ZpypQpkqS5c+cqPz9fS5cu1fLlyy/bX2VlpSorK63HFRUVkiSPxyOPx1PfU2Hx7usINg0+xtU+x/Xkfc7meO6mxFz+JVDnkgJ3thtxrkCbFQAANL9G/eq2Y8eOye12Kzk52VqLiopSUlKSCgsL9cgjj6iwsFDR0dFWUJek5ORkBQcHa/fu3XrooYdUWFioe+65R2FhYVZNamqq/vM//1OnTp1S69atVVhYqKysLJ/nT01NrfW2/EvNmzdPs2fPrrW+efNmRUZGXsPk/zR3QM01H+NKmvMt/vn5+c323E2JufxLoM4lBe5sN9Jc586da4ZOAABAIGvUsO52uyVJsbGxPuuxsbHWNrfbrZiYGN8mWrRQmzZtfGri4+NrHcO7rXXr1nK73XU+z+VkZ2f7BPyKigp16tRJKSkpcjqd9RnVh8fjUX5+vn63N1iVNUENPk5dDsxKbZLj1sU719ChQxUaGnrdn7+pMJd/CdS5pMCd7Uacy/tOLQAAgMbSqGHd7hwOhxwOR6310NDQRvmDsrImSJXVTRPWm/MP3sY6P3bDXP4lUOeSAne2G2muQJwTAAA0r0b96ra4uDhJUmlpqc96aWmptS0uLk4nTpzw2X7x4kWdPHnSp+Zyx7j0Oa5U490OAAAAAIC/atSwHh8fr7i4OBUUFFhrFRUV2r17t1wulyTJ5XKprKxMRUVFVs2WLVtUU1OjpKQkq2bHjh0+N+zJz89X9+7d1bp1a6vm0ufx1nifBwAAAAAAf1XvsH7mzBkVFxeruLhY0j9vKldcXKySkhIFBQVp0qRJ+v3vf6//+Z//0f79+/XYY4+pQ4cOGjFihCSpZ8+eGjZsmMaPH689e/bogw8+UGZmph555BF16NBBkvTLX/5SYWFhGjdunA4ePKjVq1dryZIlPp83f+aZZ7Rx40Y999xzOnz4sGbNmqW9e/cqMzPz2s8KAAAAAADNqN6fWd+7d6/uvfde67E3QKenpys3N1dTp07V2bNn9dRTT6msrEx33XWXNm7cqPDwcGuf119/XZmZmRoyZIiCg4M1cuRIvfDCC9b2qKgobd68WRkZGUpMTFS7du00Y8YMn+9i/9GPfqQ33nhD06dP129/+1vddtttWrdunXr16tWgEwEAAAAAgF3UO6wPHjxYxlz5+8SDgoI0Z84czZkz54o1bdq00RtvvFHn8/Tp00fvvfdenTU///nP9fOf/7zuhgEAAAAA8DON+pl1AAAAAABw7QjrAAAAAADYDGEdAAAAAACbIawDAAAAAGAzhHUAAAAAAGyGsA4AAAAAgM0Q1gEAAAAAsBnCOgAAAAAANkNYBwAAAADAZgjrAAAAAADYDGEdAAAAAACbIawDAAAAAGAzhHUAAAAAAGyGsA4AAAAAgM0Q1gEAAAAAsBnCOgAAAAAANkNYBwAAAADAZgjrAAAAAADYDGEdAAAAAACbIawDAAAAAGAzhHUAAAAAAGyGsA4AAAAAgM0Q1gEAAAAAsBnCOgAAAAAANkNYBwAAAADAZgjrAAAAAADYTIvmbgBXp+uzefXe54v5aU3QCQAAAACgqfHKOgAAAAAANkNYBwAAAADAZgjrAAAAAADYDGEdAAAAAACbIawDAAAAAGAzhHUAAAAAAGyGsA4AAAAAgM0Q1gEAAAAAsJkWzd0Amk7XZ/PqVf/F/LQm6gQAAAAAUB+8sg4AAAAAgM0Q1gEAAAAAsBnCOgAAAAAANuP3n1nPycnRwoUL5Xa71bdvX7344osaOHBgc7fll777GXdHiNGCgVKvWZtUWR1Uq57PuAMAAABA0/DrV9ZXr16trKwszZw5Ux999JH69u2r1NRUnThxorlbAwAAAACgwfz6lfVFixZp/PjxGjt2rCRp+fLlysvL08qVK/Xss8/Wqq+srFRlZaX1uLy8XJJ08uRJeTyeBvfh8Xh07tw5tfAEq7qm9ivQ/qpFjdG5czVXnKvbb9Y0eQ+7s4c0+jG91+vbb79VaGhoox+/uTCX/wnU2W7EuU6fPi1JMsY0R2sAACAABRk//cuiqqpKkZGR+vOf/6wRI0ZY6+np6SorK9Pbb79da59Zs2Zp9uzZ17FLAMCN5KuvvlLHjh2buw0AABAA/PaV9X/84x+qrq5WbGysz3psbKwOHz582X2ys7OVlZVlPa6pqdHJkyfVtm1bBQU1/BXxiooKderUSV999ZWcTmeDj2M3zOVfmMv/BOpsN+JcxhidPn1aHTp0aKbuAABAoPHbsN4QDodDDofDZy06OrrRju90OgPqD1Mv5vIvzOV/AnW2G22uqKioZugGAAAEKr+9wVy7du0UEhKi0tJSn/XS0lLFxcU1U1cAAAAAAFw7vw3rYWFhSkxMVEFBgbVWU1OjgoICuVyuZuwMAAAAAIBr49dvg8/KylJ6eroGDBiggQMH6vnnn9fZs2etu8NfLw6HQzNnzqz1Fnt/x1z+hbn8T6DOxlwAAADXzm/vBu+1dOlSLVy4UG63W/369dMLL7ygpKSk5m4LAAAAAIAG8/uwDgAAAABAoPHbz6wDAAAAABCoCOsAAAAAANgMYR0AAAAAAJshrAMAAAAAYDOE9WuUk5Ojrl27Kjw8XElJSdqzZ09zt+Rj3rx5+uEPf6ibbrpJMTExGjFihI4cOeJTM3jwYAUFBfn8mzBhgk9NSUmJ0tLSFBkZqZiYGE2ZMkUXL170qdm2bZv69+8vh8Ohbt26KTc3t8nmmjVrVq2ee/ToYW2/cOGCMjIy1LZtW7Vq1UojR45UaWmprWeSpK5du9aaKygoSBkZGZL851rt2LFDDzzwgDp06KCgoCCtW7fOZ7sxRjNmzFD79u0VERGh5ORkffbZZz41J0+e1JgxY+R0OhUdHa1x48bpzJkzPjWffPKJ7r77boWHh6tTp05asGBBrV7Wrl2rHj16KDw8XL1799aGDRuaZC6Px6Np06apd+/eatmypTp06KDHHntMX3/9tc8xLneN58+fb9u5JOnxxx+v1fOwYcN8avztekm67O9aUFCQFi5caNXY8XoBAIAbhEGDvfnmmyYsLMysXLnSHDx40IwfP95ER0eb0tLS5m7NkpqaalatWmUOHDhgiouLzf333286d+5szpw5Y9X85Cc/MePHjzfHjx+3/pWXl1vbL168aHr16mWSk5PNvn37zIYNG0y7du1Mdna2VfO3v/3NREZGmqysLHPo0CHz4osvmpCQELNx48YmmWvmzJnmjjvu8On5m2++sbZPmDDBdOrUyRQUFJi9e/eaQYMGmR/96Ee2nskYY06cOOEzU35+vpFktm7daozxn2u1YcMG82//9m/mL3/5i5Fk3nrrLZ/t8+fPN1FRUWbdunXm448/Nj/96U9NfHy8OX/+vFUzbNgw07dvX7Nr1y7z3nvvmW7dupnRo0db28vLy01sbKwZM2aMOXDggPnTn/5kIiIizMsvv2zVfPDBByYkJMQsWLDAHDp0yEyfPt2Ehoaa/fv3N/pcZWVlJjk52axevdocPnzYFBYWmoEDB5rExESfY3Tp0sXMmTPH5xpe+vtot7mMMSY9Pd0MGzbMp+eTJ0/61Pjb9TLG+Mxz/Phxs3LlShMUFGSOHj1q1djxegEAgBsDYf0aDBw40GRkZFiPq6urTYcOHcy8efOasau6nThxwkgy27dvt9Z+8pOfmGeeeeaK+2zYsMEEBwcbt9ttrb300kvG6XSayspKY4wxU6dONXfccYfPfqNGjTKpqamNO8D/N3PmTNO3b9/LbisrKzOhoaFm7dq11tqnn35qJJnCwkJjjD1nupxnnnnG3HrrraampsYY45/X6rshqaamxsTFxZmFCxdaa2VlZcbhcJg//elPxhhjDh06ZCSZDz/80Kr561//aoKCgsz//u//GmOMWbZsmWndurU1lzHGTJs2zXTv3t16/Itf/MKkpaX59JOUlGR+9atfNfpcl7Nnzx4jyXz55ZfWWpcuXczixYuvuI8d50pPTzcPPvjgFfcJlOv14IMPmvvuu89nze7XCwAABC7eBt9AVVVVKioqUnJysrUWHBys5ORkFRYWNmNndSsvL5cktWnTxmf99ddfV7t27dSrVy9lZ2fr3Llz1rbCwkL17t1bsbGx1lpqaqoqKip08OBBq+bSc+Gtacpz8dlnn6lDhw665ZZbNGbMGJWUlEiSioqK5PF4fPrp0aOHOnfubPVj15kuVVVVpddee01PPPGEgoKCrHV/vFaXOnbsmNxut08PUVFRSkpK8rk+0dHRGjBggFWTnJys4OBg7d6926q55557FBYW5jPHkSNHdOrUKaumOWctLy9XUFCQoqOjfdbnz5+vtm3b6s4779TChQt9PqZg17m2bdummJgYde/eXRMnTtS3337r07O/X6/S0lLl5eVp3Lhxtbb54/UCAAD+r0VzN+Cv/vGPf6i6utonFElSbGysDh8+3Exd1a2mpkaTJk3Sj3/8Y/Xq1cta/+Uvf6kuXbqoQ4cO+uSTTzRt2jQdOXJEf/nLXyRJbrf7snN6t9VVU1FRofPnzysiIqJRZ0lKSlJubq66d++u48ePa/bs2br77rt14MABud1uhYWF1QpIsbGx39tvc870XevWrVNZWZkef/xxa80fr9V3efu4XA+X9hgTE+OzvUWLFmrTpo1PTXx8fK1jeLe1bt36irN6j9GULly4oGnTpmn06NFyOp3W+r/+67+qf//+atOmjXbu3Kns7GwdP35cixYtsnq321zDhg3Tww8/rPj4eB09elS//e1vNXz4cBUWFiokJCQgrterr76qm266SQ8//LDPuj9eLwAAEBgI6zeQjIwMHThwQO+//77P+lNPPWX93Lt3b7Vv315DhgzR0aNHdeutt17vNq/K8OHDrZ/79OmjpKQkdenSRWvWrGnysHm9rFixQsOHD1eHDh2sNX+8Vjcij8ejX/ziFzLG6KWXXvLZlpWVZf3cp08fhYWF6Ve/+pXmzZsnh8NxvVu9Ko888oj1c+/evdWnTx/deuut2rZtm4YMGdKMnTWelStXasyYMQoPD/dZ98frBQAAAgNvg2+gdu3aKSQkpNYdxktLSxUXF9dMXV1ZZmam1q9fr61bt6pjx4511iYlJUmSPv/8c0lSXFzcZef0bqurxul0XpfwHB0drdtvv12ff/654uLiVFVVpbKyslr9fF+/3m111VyPmb788ku9++67evLJJ+us88dr5e2jrt+duLg4nThxwmf7xYsXdfLkyUa5hk35O+oN6l9++aXy8/N9XlW/nKSkJF28eFFffPGFJPvOdalbbrlF7dq18/nvzl+vlyS99957OnLkyPf+vkn+eb0AAIB/Iqw3UFhYmBITE1VQUGCt1dTUqKCgQC6Xqxk782WMUWZmpt566y1t2bKl1ts1L6e4uFiS1L59e0mSy+XS/v37ff4Y94aQhIQEq+bSc+GtuV7n4syZMzp69Kjat2+vxMREhYaG+vRz5MgRlZSUWP3YfaZVq1YpJiZGaWlpddb547WKj49XXFycTw8VFRXavXu3z/UpKytTUVGRVbNlyxbV1NRY/4PC5XJpx44d8ng8PnN0795drVu3tmqu56zeoP7ZZ5/p3XffVdu2bb93n+LiYgUHB1tvI7fjXN/197//Xd9++63Pf3f+eL28VqxYocTERPXt2/d7a/3xegEAAD/V3He482dvvvmmcTgcJjc31xw6dMg89dRTJjo62udO3M1t4sSJJioqymzbts3nq4fOnTtnjDHm888/N3PmzDF79+41x44dM2+//ba55ZZbzD333GMdw/t1YCkpKaa4uNhs3LjR3HzzzZf9OrApU6aYTz/91OTk5DTp15z9+te/Ntu2bTPHjh0zH3zwgUlOTjbt2rUzJ06cMMb886vbOnfubLZs2WL27t1rXC6Xcblctp7Jq7q62nTu3NlMmzbNZ92frtXp06fNvn37zL59+4wks2jRIrNv3z7rrujz58830dHR5u233zaffPKJefDBBy/71W133nmn2b17t3n//ffNbbfd5vNVYGVlZSY2NtY8+uij5sCBA+bNN980kZGRtb4yq0WLFuYPf/iD+fTTT83MmTOv6Suz6pqrqqrK/PSnPzUdO3Y0xcXFPr9v3juF79y50yxevNgUFxebo0ePmtdee83cfPPN5rHHHrPtXKdPnza/+c1vTGFhoTl27Jh59913Tf/+/c1tt91mLly4YB3D366XV3l5uYmMjDQvvfRSrf3ter0AAMCNgbB+jV588UXTuXNnExYWZgYOHGh27drV3C35kHTZf6tWrTLGGFNSUmLuuece06ZNG+NwOEy3bt3MlClTfL672xhjvvjiCzN8+HATERFh2rVrZ379618bj8fjU7N161bTr18/ExYWZm655RbrOZrCqFGjTPv27U1YWJj5wQ9+YEaNGmU+//xza/v58+fNv/zLv5jWrVubyMhI89BDD5njx4/beiavTZs2GUnmyJEjPuv+dK22bt162f/u0tPTjTH//Pq23/3udyY2NtY4HA4zZMiQWvN+++23ZvTo0aZVq1bG6XSasWPHmtOnT/vUfPzxx+auu+4yDofD/OAHPzDz58+v1cuaNWvM7bffbsLCwswdd9xh8vLymmSuY8eOXfH3bevWrcYYY4qKikxSUpKJiooy4eHhpmfPnuY//uM/fEKv3eY6d+6cSUlJMTfffLMJDQ01Xbp0MePHj6/1PyX97Xp5vfzyyyYiIsKUlZXV2t+u1wsAANwYgowxpklfugcAAAAAAPXCZ9YBAAAAALAZwjoAAAAAADZDWAcAAAAAwGYI6wAAAAAA2AxhHQAAAAAAmyGsAwAAAABgM4R1AAAAAABshrAOAAAAAIDNENYBAAAAALAZwjoAAAAAADZDWAcAAAAAwGb+H06uCTb21/J8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive Statistics for Character Counts:\n",
      "       num_characters_instruction  num_characters_input  num_characters_output\n",
      "count                68912.000000          68912.000000           68912.000000\n",
      "mean                    60.443377             17.328172             459.677357\n",
      "std                     21.580738             57.041907             610.331656\n",
      "min                      9.000000              0.000000               0.000000\n",
      "25%                     46.000000              0.000000              76.000000\n",
      "50%                     57.000000              0.000000             302.000000\n",
      "75%                     71.000000             13.000000             577.000000\n",
      "max                    489.000000           2625.000000           16984.000000\n",
      "\n",
      "Missing Values in Each Column:\n",
      "output                        0\n",
      "input                         0\n",
      "instruction                   0\n",
      "text                          0\n",
      "num_characters_instruction    0\n",
      "num_characters_input          0\n",
      "num_characters_output         0\n",
      "dtype: int64\n",
      "\n",
      "Unique Values in Each Column:\n",
      "output                        67853\n",
      "input                         18882\n",
      "instruction                   58482\n",
      "text                              1\n",
      "num_characters_instruction      216\n",
      "num_characters_input            544\n",
      "num_characters_output          3240\n",
      "dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame and it's already loaded\n",
    "\n",
    "# Basic Dataset Information\n",
    "print(\"Basic Dataset Information:\")\n",
    "print(f\"Number of Rows: {df.shape[0]}\")\n",
    "print(f\"Number of Columns: {df.shape[1]}\")\n",
    "print(f\"Column Names: {df.columns.tolist()}\", end=\"\\n\\n\")\n",
    "\n",
    "# Memory Usage\n",
    "print(\"Memory Usage by Column:\")\n",
    "print(df.memory_usage(deep=True), end=\"\\n\\n\")\n",
    "\n",
    "# Data Types\n",
    "print(\"Data Types of Each Column:\")\n",
    "print(df.dtypes, end=\"\\n\\n\")\n",
    "\n",
    "# Calculating the length of each cell in each column\n",
    "analysis_df = df.copy()\n",
    "analysis_df['num_characters_instruction'] = analysis_df['instruction'].apply(len)\n",
    "analysis_df['num_characters_input'] = analysis_df['input'].apply(len)\n",
    "analysis_df['num_characters_output'] = analysis_df['output'].apply(len)\n",
    "\n",
    "# Show Distribution\n",
    "analysis_df.hist(column=['num_characters_instruction', 'num_characters_input', 'num_characters_output'], bins=30, figsize=(12, 8))\n",
    "plt.suptitle('Distribution of Character Counts in Each Column')\n",
    "plt.show()\n",
    "\n",
    "# Descriptive Statistics for Character Counts\n",
    "print(\"Descriptive Statistics for Character Counts:\")\n",
    "print(analysis_df[['num_characters_instruction', 'num_characters_input', 'num_characters_output']].describe(), end=\"\\n\\n\")\n",
    "\n",
    "# Additional Detailed Statistics\n",
    "max_chars_instruction = analysis_df['num_characters_instruction'].max()\n",
    "max_chars_input = analysis_df['num_characters_input'].max()\n",
    "max_chars_output = analysis_df['num_characters_output'].max()\n",
    "\n",
    "min_chars_instruction = analysis_df['num_characters_instruction'].min()\n",
    "min_chars_input = analysis_df['num_characters_input'].min()\n",
    "min_chars_output = analysis_df['num_characters_output'].min()\n",
    "\n",
    "# Print detailed statistics\n",
    "# Missing Values\n",
    "print(\"Missing Values in Each Column:\")\n",
    "print(analysis_df.isnull().sum(), end=\"\\n\\n\")\n",
    "\n",
    "# Unique Values\n",
    "print(\"Unique Values in Each Column:\")\n",
    "print(analysis_df.nunique(), end=\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac61500-8a23-44a5-ad87-5de1dd39ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# BitsAndBytesConfig allows the configuration of the BitsAndBytes feature of Hugging Face Transformers.\n",
    "# This feature enables efficient model inference by reducing the model size and computational requirements.\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enables loading the model in a 4-bit quantized format to reduce memory usage.\n",
    "    bnb_4bit_use_double_quant=True,  # Activates double quantization, which quantizes not just the weights but also the activations.\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Sets the quantization type to 'nf4', a 4-bit number format for quantization.\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16  # Specifies bfloat16 as the data type for computation, balancing precision and speed.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf7aae13-f176-4b35-8f97-459c38e359ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d90c67ca512048c19d511b447336196e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is the identifier for the model we want to load from Hugging Face's model repository.\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\"\n",
    "\n",
    "# Load the pre-trained causal language model from Hugging Face with the specified model ID.\n",
    "# The model is configured for quantization using the previously defined BitsAndBytesConfig to improve efficiency.\n",
    "# 'device_map=\"auto\"' allows the model to be placed on the most appropriate device (CPU/GPU) automatically.\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "# Load the tokenizer associated with the pre-trained model.\n",
    "# The tokenizer is responsible for converting input text into a format that the model can understand (tokens).\n",
    "# 'add_eos_token=True' ensures that the end-of-sentence token is appended to the input sequences.\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b153a46a-4104-4efe-81a8-d4c81c98aede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Here is a task that requires an informative response. Please complete the task based on the provided instruction.\n",
      "\n",
      "    ### Instruction:\n",
      "    Will capital gains affect my tax bracket?\n",
      "\n",
      "    ### Completion:\n",
      "     Hinweis: Wenn Sie dieses Skript verwenden, mssen Sie die `Microsoft.Azure.Commands.Network` Modul-Versionsnummer aktualisieren, indem Sie die `Update-Module -Name Microsoft.Azure.Commands.Network -RepositoryPublishLocation \"https://www.powershellgallery.com/api/v2/\"` Befehl ausfhren.\n",
      "\n",
      "# <a name=\"version10\"></a>Version 1.0\n",
      "## <a name=\"parameters\"></a>Parameter\n",
      "### <a name=\"-subscription\"></a>-Abonnement\n",
      "Geben Sie ein Abonnement-ID, ein Abonnement-Name oder einen Abonnement-Name an, um das Abonnement auszugeben, das Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-resourcegroup\"></a>-Ressourcengruppe\n",
      "Geben Sie den Namen der Ressourcengruppe an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-location\"></a>-Standort\n",
      "Geben Sie den Standort an, in dem die Ressourcengruppe gehostet wird, an, um die Ressourcengruppe auszuwhlen.\n",
      "\n",
      "### <a name=\"-network\"></a>-Netzwerk\n",
      "Geben Sie den Namen des Netzwerks an, das Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-virtualnetwork\"></a>-VirtualNetwork\n",
      "Geben Sie den Namen des virtuellen Netzwerks an, das Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-subnet\"></a>-Subnetz\n",
      "Geben Sie den Namen des Subnetzes an, das Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-networkinterface\"></a>-Netzwerkschnittstelle\n",
      "Geben Sie den Namen der Netzwerkschnittstelle an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-virtualmachine\"></a>-VirtualMachine\n",
      "Geben Sie den Namen der virtuellen Computer an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-nicname\"></a>-NicName\n",
      "Geben Sie den Namen der NIC an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-ipaddress\"></a>-IP-Adresse\n",
      "Geben Sie die IP-Adresse an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-ipconfiguration\"></a>-IP-Konfiguration\n",
      "Geben Sie den Namen der IP-Konfiguration an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-nicname\"></a>-NicName\n",
      "Geben Sie den Namen der NIC an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-ipaddress\"></a>-IP-Adresse\n",
      "Geben Sie die IP-Adresse an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-subnet\"></a>-Subnetz\n",
      "Geben Sie den Namen des Subnetzes an, das Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-nicname\"></a>-NicName\n",
      "Geben Sie den Namen der NIC an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-ipaddress\"></a>-IP-Adresse\n",
      "Geben Sie die IP-Adresse an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-nicname\"></a>-NicName\n",
      "Geben Sie den Namen der NIC an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-ipaddress\"></a>-IP-Adresse\n",
      "Geben Sie die IP-Adresse an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-nicname\"></a>-NicName\n",
      "Geben Sie den Namen der NIC an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-ipaddress\"></a>-IP-Adresse\n",
      "Geben Sie die IP-Adresse an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-nicname\"></a>-NicName\n",
      "Geben Sie den Namen der NIC an, die Sie verwenden mchten.\n",
      "\n",
      "### <a name=\"-ipaddress\"></a>-IP-Adresse\n",
      "Geben Sie die IP-Adresse an, die\n"
     ]
    }
   ],
   "source": [
    "# Generate a response from the model for a specified query using the 'create_model_response' function.\n",
    "# The query here is \"Will capital gains affect my tax bracket?\"\n",
    "# 'base_model' is the loaded language model and 'base_tokenizer' is the corresponding tokenizer.\n",
    "# The function will process the query, generate a response using the model, and return the result as a string.\n",
    "result = create_model_response(task_query=\"Will capital gains affect my tax bracket?\", inference_model=base_model, sequence_tokenizer=base_tokenizer)\n",
    "\n",
    "# Print the result to display the model-generated response to the query.\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f8abb82-66ef-4384-b412-9043b86a4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contextual_prompt(data_point):\n",
    "    \"\"\"\n",
    "    Generates a textual prompt incorporating instructions, optional context, and a response.\n",
    "\n",
    "    :param data_point: A dictionary containing instruction, optional input context, and output.\n",
    "    :return: A string representing a formatted and contextualized prompt.\n",
    "    \"\"\"\n",
    "    instruction = data_point[\"instruction\"]\n",
    "    input_context = data_point.get(\"input\")\n",
    "    response = data_point[\"output\"]\n",
    "\n",
    "    # Base prompt structure\n",
    "    text = 'This is a task instruction. Complete the task as described.\\n\\n'\n",
    "\n",
    "    # Adding instruction\n",
    "    text += f'### Instruction:\\n{instruction}\\n\\n'\n",
    "\n",
    "    # Conditionally adding input context if available\n",
    "    if input_context:\n",
    "        text += f'### Context:\\n{input_context}\\n\\n'\n",
    "\n",
    "    # Adding the response\n",
    "    text += f'### Response:\\n{response}'\n",
    "\n",
    "    return text\n",
    "\n",
    "# Applying the function to each data point and adding the resulting prompts as a new column\n",
    "text_column = [create_contextual_prompt(data_point) for data_point in data]\n",
    "data = data.add_column(\"prompt\", text_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec8749e-2236-4a3b-b40c-b504e2949505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to ensure that the order of data points does not introduce any bias.\n",
    "# A fixed seed (1234 in this case) is used for reproducibility, ensuring the shuffle order remains consistent across runs.\n",
    "data = data.shuffle(seed=1234)\n",
    "\n",
    "# Apply the tokenizer to each data point in the dataset.\n",
    "# The 'map' function applies the given lambda function to each element of the dataset.\n",
    "# 'base_tokenizer(samples[\"prompt\"])' tokenizes the 'prompt' field of each sample in the dataset.\n",
    "# 'batched=True' indicates that the tokenization should be done in batches for efficiency.\n",
    "data = data.map(lambda samples: base_tokenizer(samples[\"prompt\"]), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc23fb0e-efc0-4952-8da6-615f8c935975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets.\n",
    "# The 'train_test_split' method divides the data, allocating 10% for testing and the rest for training.\n",
    "# The 'test_size=0.1' parameter specifies that 10% of the dataset should be used for the test set.\n",
    "data = data.train_test_split(test_size=0.1)\n",
    "\n",
    "# Extract the training data subset from the split.\n",
    "# The 'train' key accesses the portion of the dataset designated for training purposes.\n",
    "train_data = data[\"train\"]\n",
    "\n",
    "# Extract the testing data subset from the split.\n",
    "# The 'test' key accesses the portion of the dataset designated for testing purposes.\n",
    "test_data = data[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e904f94-80ef-4130-bf9b-8e6699aa84b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['output', 'input', 'instruction', 'text', 'prompt', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 62020\n",
      "})\n",
      "Dataset({\n",
      "    features: ['output', 'input', 'instruction', 'text', 'prompt', 'input_ids', 'attention_mask'],\n",
      "    num_rows: 6892\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80b3bf0c-ae44-4d0c-abc4-f1670c7b5770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LlamaForCausalLM(\n",
      "  (model): LlamaModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x LlamaDecoderLayer(\n",
      "        (self_attn): LlamaAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): LlamaRotaryEmbedding()\n",
      "        )\n",
      "        (mlp): LlamaMLP(\n",
      "          (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
      "          (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
      "          (act_fn): SiLU()\n",
      "        )\n",
      "        (input_layernorm): LlamaRMSNorm()\n",
      "        (post_attention_layernorm): LlamaRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): LlamaRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Import the function for preparing a model for k-bit training.\n",
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "# Enable gradient checkpointing for the base model.\n",
    "# Gradient checkpointing is a technique to reduce memory usage during training by saving only a subset of the intermediate activations.\n",
    "# This allows for training larger models or using larger batch sizes.\n",
    "base_model.gradient_checkpointing_enable()\n",
    "\n",
    "# Prepare the base model for k-bit training.\n",
    "# The 'prepare_model_for_kbit_training' function presumably configures the model for training with reduced precision (k-bit),\n",
    "# which can lead to efficiency improvements in both memory usage and computational speed.\n",
    "base_model = prepare_model_for_kbit_training(base_model)\n",
    "\n",
    "# Print the model configuration.\n",
    "print(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "058491cf-6da9-4a4a-9861-60f5d83a7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bitsandbytes as bnb\n",
    "\n",
    "def get_linear_layer_names(model, bit_precision=4):\n",
    "    \"\"\"\n",
    "    Identifies and returns the names of linear layers in the model based on the specified bit precision.\n",
    "\n",
    "    :param model: The neural network model to be inspected.\n",
    "    :param bit_precision: The bit precision of the linear layers to find (default: 4).\n",
    "    :return: A list of names of the linear layers in the model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the class type for the linear layer based on bit precision.\n",
    "    linear_class = bnb.nn.Linear4bit if bit_precision == 4 else bnb.nn.Linear8bitLt if bit_precision == 8 else torch.nn.Linear\n",
    "\n",
    "    linear_layer_names = set()  # Set to store unique names of linear layers.\n",
    "\n",
    "    # Iterate through all modules in the model to find instances of the specified linear layer class.\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, linear_class):\n",
    "            # Extract the base or last segment of the module name and add it to the set.\n",
    "            module_name_segment = name.split('.')[0 if name.count('.') == 0 else -1]\n",
    "            linear_layer_names.add(module_name_segment)\n",
    "\n",
    "    # Remove 'lm_head' from the set if present, typically applicable for 16-bit precision models.\n",
    "    linear_layer_names.discard('lm_head')\n",
    "\n",
    "    return list(linear_layer_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29616afa-b38e-4a8c-958f-9ead1c349fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k_proj', 'v_proj', 'o_proj', 'up_proj', 'q_proj', 'down_proj', 'gate_proj']\n"
     ]
    }
   ],
   "source": [
    "modules = get_linear_layer_names(base_model)\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c9e8ce3-d94d-4387-b634-6c1920cbfce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model  # Importing LoraConfig and get_peft_model from the 'peft' package.\n",
    "\n",
    "# Create a configuration object for LORA (Low-Rank Adaptation) layers.\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  # 'r' is the rank of the LORA layers, affecting the amount of parameters added.\n",
    "    lora_alpha=32,  # 'lora_alpha' is a scaling factor for LORA's low-rank matrices.\n",
    "    target_modules=modules,  # 'target_modules' are the modules in the model to be adapted by LORA.\n",
    "    lora_dropout=0.05,  # 'lora_dropout' specifies the dropout rate in LORA layers for regularization.\n",
    "    bias=\"none\",  # 'bias' determines the usage of bias in LORA layers, here set to 'none'.\n",
    "    task_type=\"CAUSAL_LM\"  # 'task_type' specifies the type of task, here set to causal language modeling.\n",
    ")\n",
    "\n",
    "# Enhance the base model with PEFT (Parameter-Efficient Fine-Tuning) using the specified LORA configuration.\n",
    "# This process involves applying the LORA adaptations to the specified target modules in the model.\n",
    "base_model = get_peft_model(base_model, lora_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "864e49ed-875f-4b25-a6d6-4480c4f40b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable: 19988480 | total: 6758404096 | Percentage: 0.2958%\n"
     ]
    }
   ],
   "source": [
    "trainable, total = base_model.get_nb_trainable_parameters()\n",
    "print(f\"Trainable: {trainable} | total: {total} | Percentage: {trainable/total*100:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13a1ea29-e992-4173-80ee-f0b8f83a6e10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n",
      "/opt/app-root/lib64/python3.9/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf1183fe77f4ae4b8008f725d6c4ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/62020 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83da3876c2d45e3a4be8998f2f5ffaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers  # Importing the transformers library, which provides tools for working with transformer models.\n",
    "\n",
    "from trl import SFTTrainer  # Importing SFTTrainer from the trl (transformer reinforcement learning) package.\n",
    "\n",
    "# Setting the padding token of the tokenizer to be the same as its end-of-sentence token.\n",
    "base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "\n",
    "# Clearing the GPU cache to free up memory and avoid potential out-of-memory issues.\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Initializing the Supervised Fine-Tuning (SFT) Trainer.\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,  # The model to be fine-tuned.\n",
    "    train_dataset=train_data,  # The dataset for training.\n",
    "    eval_dataset=test_data,  # The dataset for evaluation.\n",
    "    dataset_text_field=\"prompt\",  # The field in the dataset that contains the text to be processed.\n",
    "    peft_config=lora_config,  # The PEFT (Parameter-Efficient Fine-Tuning) configuration, here using LORA.\n",
    "    args=transformers.TrainingArguments(  # Configuration for the training process.\n",
    "        per_device_train_batch_size=1,  # Batch size per device.\n",
    "        gradient_accumulation_steps=16,  # Number of steps to accumulate gradients before updating model weights.\n",
    "        warmup_steps=50,  # Absolute number of warmup steps for the learning rate scheduler.\n",
    "        max_steps=-1,  # Maximum number of training steps, -1 means unlimited.\n",
    "        learning_rate=1e-5,  # The learning rate for optimization.\n",
    "        logging_dir=\"./logs\",  # Directory where training logs will be stored.\n",
    "        logging_first_step=True,  # Log the first training step, useful for debugging.\n",
    "        logging_steps=20,  # Frequency of logging training information.\n",
    "        evaluation_strategy=\"steps\",  # Strategy to perform model evaluation.\n",
    "        optim=\"adamw_torch\",  # The optimizer to be used.\n",
    "        eval_steps=50,  # Number of steps before performing evaluation.\n",
    "        output_dir=\"/opt/app-root/src/data/v8-finance-3/outputs\",  # Directory to store output files.\n",
    "        load_best_model_at_end=True,  # Whether to load the best model at the end of training.\n",
    "    ),\n",
    "    data_collator=transformers.DataCollatorForLanguageModeling(base_tokenizer, mlm=False),  # Data collator for language modeling.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc80bdb-f837-4283-ad93-b28346a47c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable caching in the model's configuration. \n",
    "# This is typically done during training to save memory, as caching activations is not necessary.\n",
    "# However, for inference, caching should be re-enabled for improved performance.\n",
    "base_model.config.use_cache = False\n",
    "\n",
    "# Start the training process using the SFTTrainer instance.\n",
    "# The function argument specifies the path to resume training from a specific checkpoint.\n",
    "trainer.train(\"/opt/app-root/src/data/v8-finance-3/outputs/checkpoint-9000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01f6772e-ade0-472e-b76e-744f43d0787f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25d7b07445f944f493eb85a8b6fc9483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/80.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/bkpandey/Llama-2-7b-hf_finetuned_finance_jupyter/commit/fcf9718d2be2b9f56d69b9cc63294b4b124ef2c8', commit_message='Upload tokenizer', commit_description='', oid='fcf9718d2be2b9f56d69b9cc63294b4b124ef2c8', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Push the fine-tuned model to the Hugging Face Model Hub.\n",
    "# This makes the model available online for others to use and download.\n",
    "# \"Llama-2-7b-hf_finetuned_finance_jupyter_v7\" is the repository name on the Model Hub.\n",
    "base_model.push_to_hub(\"Llama-2-7b-hf_finetuned_finance_jupyter\")\n",
    "\n",
    "# Similarly, push the tokenizer associated with the fine-tuned model to the Hugging Face Model Hub.\n",
    "# This ensures that users who download the model also have access to the correct tokenizer.\n",
    "# The repository name is kept the same for consistency and easy association with the model.\n",
    "base_tokenizer.push_to_hub(\"Llama-2-7b-hf_finetuned_finance_jupyter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a66ef37c-1b3e-4f7d-b3f3-734816a3a613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3d63a9ef86349728abfeb68abed4be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/568 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c499781328344aeaad69699341ae092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1629ba3953a9481d93dc02a5eae7c226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/80.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel, PeftConfig  # Import PEFT (Parameter-Efficient Fine-Tuning) related classes.\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer  # Importing necessary classes from transformers.\n",
    "\n",
    "# Identifier for the fine-tuned PEFT model on the Hugging Face Model Hub.\n",
    "peft_model_id = \"bkpandey/Llama-2-7b-hf_finetuned_finance_jupyter\"\n",
    "\n",
    "# Load the PEFT configuration from the Hugging Face Model Hub using the model identifier.\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "\n",
    "# Load the base causal language model specified in the PEFT config, enabling 4-bit loading for efficiency.\n",
    "# 'device_map=\"auto\"' automatically places the model on the most appropriate device (CPU/GPU).\n",
    "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_4bit=True, device_map='auto')\n",
    "\n",
    "# Load the tokenizer corresponding to the base model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "# Load the PEFT model from the pretrained model and config, enabling the use of PEFT enhancements.\n",
    "model = PeftModel.from_pretrained(model, peft_model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "756ad9d2-6313-4ee1-87c4-7d5e73aa0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.9/site-packages/bitsandbytes/nn/modules.py:226: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Here is a task that requires an informative response. Please complete the task based on the provided instruction.\n",
      "\n",
      "    ### Instruction:\n",
      "    Will capital gains affect my tax bracket?\n",
      "\n",
      "    ### Completion:\n",
      "    \n",
      "    Yes, capital gains will affect your tax bracket. Capital gains are considered income and are taxed at the same rate as other forms of income. This means that any capital gains you make will be added to your total income for the year and you will be taxed accordingly.\n",
      "\n",
      "    In addition, if you make a lot of capital gains in a single year, you may be pushed into a higher tax bracket than you would have been in otherwise. For example, if you make $100,000 in capital gains in a single year, you may be pushed into the next tax bracket, which could increase your tax bill significantly.\n",
      "\n",
      "    Therefore, it is important to keep track of your capital gains and losses and plan accordingly when it comes to taxes.\n",
      "\n",
      "    ### Note:\n",
      "    Capital gains are the profits you make when you sell a capital asset, such as stocks, bonds, and property. Capital losses are the losses you incur when you sell a capital asset for less than you paid for it. Capital gains and losses are added to your total income for the year and are taxed at the same rate as other forms of income.\n"
     ]
    }
   ],
   "source": [
    "result = create_model_response(task_query=\"Will capital gains affect my tax bracket?\", inference_model=model, sequence_tokenizer=tokenizer)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013553a-b5fe-4f48-831d-1de0afd26079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
